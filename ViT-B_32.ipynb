{"cells":[{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yDdGkB5Ff0sH","executionInfo":{"status":"ok","timestamp":1664211171772,"user_tz":-120,"elapsed":13,"user":{"displayName":"Yueying CAO","userId":"04257612248168992935"}},"outputId":"8f940161-8b11-4096-d0e4-f313e9656a7a"},"id":"yDdGkB5Ff0sH","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Sep 26 16:52:51 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   46C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kGACyV1G7V8d","executionInfo":{"status":"ok","timestamp":1664211173955,"user_tz":-120,"elapsed":2190,"user":{"displayName":"Yueying CAO","userId":"04257612248168992935"}},"outputId":"e221d0ce-3889-4a36-d9b7-dac6e7e26650"},"id":"kGACyV1G7V8d","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","path=\"/content/drive/MyDrive/Code/ViT-pytorch-main\"\n","os.chdir(path)\n","os.listdir(path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i-nmwq0DtIvO","executionInfo":{"status":"ok","timestamp":1664211173956,"user_tz":-120,"elapsed":13,"user":{"displayName":"Yueying CAO","userId":"04257612248168992935"}},"outputId":"6e19de51-bc35-4a7f-9852-4c55294d0078"},"id":"i-nmwq0DtIvO","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['LICENSE',\n"," '.gitignore',\n"," 'visualize_attention_map.ipynb',\n"," 'README.md',\n"," 'requirements.txt',\n"," 'ngrok',\n"," 'img',\n"," 'data',\n"," 'logs',\n"," 'models',\n"," 'output',\n"," 'utils',\n"," 'checkpoint',\n"," '.ipynb_checkpoints',\n"," 'ViT-B_16-224.ipynb',\n"," 'apex']"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# !git clone https://github.com/NVIDIA/apex\n","%cd apex\n","!python3 setup.py install"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T-zIylQE7oY4","executionInfo":{"status":"ok","timestamp":1664211186096,"user_tz":-120,"elapsed":12149,"user":{"displayName":"Yueying CAO","userId":"04257612248168992935"}},"outputId":"d346d08e-2dfd-4e33-ce52-d35caafcc843"},"id":"T-zIylQE7oY4","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code/ViT-pytorch-main/apex\n","\n","\n","torch.__version__  = 1.12.1+cu113\n","\n","\n","running install\n","running bdist_egg\n","running egg_info\n","writing apex.egg-info/PKG-INFO\n","writing dependency_links to apex.egg-info/dependency_links.txt\n","writing top-level names to apex.egg-info/top_level.txt\n","adding license file 'LICENSE'\n","writing manifest file 'apex.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/apex\n","copying build/lib/apex/__init__.py -> build/bdist.linux-x86_64/egg/apex\n","copying build/lib/apex/_autocast_utils.py -> build/bdist.linux-x86_64/egg/apex\n","creating build/bdist.linux-x86_64/egg/apex/RNN\n","copying build/lib/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/egg/apex/RNN\n","copying build/lib/apex/RNN/__init__.py -> build/bdist.linux-x86_64/egg/apex/RNN\n","copying build/lib/apex/RNN/cells.py -> build/bdist.linux-x86_64/egg/apex/RNN\n","copying build/lib/apex/RNN/models.py -> build/bdist.linux-x86_64/egg/apex/RNN\n","creating build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/__version__.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/_initialize.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/amp.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/frontend.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/handle.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/opt.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/scaler.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/utils.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/wrap.py -> build/bdist.linux-x86_64/egg/apex/amp\n","creating build/bdist.linux-x86_64/egg/apex/amp/lists\n","copying build/lib/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n","copying build/lib/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n","copying build/lib/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n","copying build/lib/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n","creating build/bdist.linux-x86_64/egg/apex/contrib\n","copying build/lib/apex/contrib/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib\n","creating build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n","copying build/lib/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n","copying build/lib/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n","copying build/lib/apex/contrib/bottleneck/halo_exchangers.py -> build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n","copying build/lib/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n","creating build/bdist.linux-x86_64/egg/apex/contrib/clip_grad\n","copying build/lib/apex/contrib/clip_grad/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/clip_grad\n","copying build/lib/apex/contrib/clip_grad/clip_grad.py -> build/bdist.linux-x86_64/egg/apex/contrib/clip_grad\n","creating build/bdist.linux-x86_64/egg/apex/contrib/conv_bias_relu\n","copying build/lib/apex/contrib/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/conv_bias_relu\n","copying build/lib/apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/bdist.linux-x86_64/egg/apex/contrib/conv_bias_relu\n","creating build/bdist.linux-x86_64/egg/apex/contrib/cudnn_gbn\n","copying build/lib/apex/contrib/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/cudnn_gbn\n","copying build/lib/apex/contrib/cudnn_gbn/batch_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/cudnn_gbn\n","creating build/bdist.linux-x86_64/egg/apex/contrib/fmha\n","copying build/lib/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/fmha\n","copying build/lib/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/egg/apex/contrib/fmha\n","creating build/bdist.linux-x86_64/egg/apex/contrib/focal_loss\n","copying build/lib/apex/contrib/focal_loss/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/focal_loss\n","copying build/lib/apex/contrib/focal_loss/focal_loss.py -> build/bdist.linux-x86_64/egg/apex/contrib/focal_loss\n","creating build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n","copying build/lib/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n","copying build/lib/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n","creating build/bdist.linux-x86_64/egg/apex/contrib/index_mul_2d\n","copying build/lib/apex/contrib/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/index_mul_2d\n","copying build/lib/apex/contrib/index_mul_2d/index_mul_2d.py -> build/bdist.linux-x86_64/egg/apex/contrib/index_mul_2d\n","creating build/bdist.linux-x86_64/egg/apex/contrib/layer_norm\n","copying build/lib/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/layer_norm\n","copying build/lib/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/layer_norm\n","creating build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","copying build/lib/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","copying build/lib/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","copying build/lib/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","copying build/lib/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","creating build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n","copying build/lib/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n","copying build/lib/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n","copying build/lib/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n","copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n","copying build/lib/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n","copying build/lib/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n","copying build/lib/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n","creating build/bdist.linux-x86_64/egg/apex/contrib/peer_memory\n","copying build/lib/apex/contrib/peer_memory/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/peer_memory\n","copying build/lib/apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/bdist.linux-x86_64/egg/apex/contrib/peer_memory\n","copying build/lib/apex/contrib/peer_memory/peer_memory.py -> build/bdist.linux-x86_64/egg/apex/contrib/peer_memory\n","creating build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n","copying build/lib/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n","copying build/lib/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n","copying build/lib/apex/contrib/sparsity/permutation_lib.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n","copying build/lib/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n","creating build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n","copying build/lib/apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n","copying build/lib/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n","copying build/lib/apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n","copying build/lib/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n","copying build/lib/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n","creating build/bdist.linux-x86_64/egg/apex/contrib/test\n","copying build/lib/apex/contrib/test/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test\n","creating build/bdist.linux-x86_64/egg/apex/contrib/test/bottleneck\n","copying build/lib/apex/contrib/test/bottleneck/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/bottleneck\n","copying build/lib/apex/contrib/test/bottleneck/test_bottleneck_module.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/bottleneck\n","creating build/bdist.linux-x86_64/egg/apex/contrib/test/clip_grad\n","copying build/lib/apex/contrib/test/clip_grad/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/clip_grad\n","copying build/lib/apex/contrib/test/clip_grad/test_clip_grad.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/clip_grad\n","creating build/bdist.linux-x86_64/egg/apex/contrib/test/conv_bias_relu\n","copying build/lib/apex/contrib/test/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/conv_bias_relu\n","copying build/lib/apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/conv_bias_relu\n","creating build/bdist.linux-x86_64/egg/apex/contrib/test/cudnn_gbn\n","copying build/lib/apex/contrib/test/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/cudnn_gbn\n","copying build/lib/apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/cudnn_gbn\n","creating build/bdist.linux-x86_64/egg/apex/contrib/test/fmha\n","copying build/lib/apex/contrib/test/fmha/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/fmha\n","copying build/lib/apex/contrib/test/fmha/test_fmha.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/fmha\n","creating build/bdist.linux-x86_64/egg/apex/contrib/test/focal_loss\n","copying build/lib/apex/contrib/test/focal_loss/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/focal_loss\n","copying build/lib/apex/contrib/test/focal_loss/test_focal_loss.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/focal_loss\n","creating build/bdist.linux-x86_64/egg/apex/contrib/test/index_mul_2d\n","copying build/lib/apex/contrib/test/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/index_mul_2d\n","copying build/lib/apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/index_mul_2d\n","creating build/bdist.linux-x86_64/egg/apex/contrib/test/layer_norm\n","copying build/lib/apex/contrib/test/layer_norm/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/layer_norm\n","copying build/lib/apex/contrib/test/layer_norm/test_fast_layer_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/layer_norm\n","creating build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n","copying build/lib/apex/contrib/test/multihead_attn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n","copying build/lib/apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n","copying build/lib/apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n","copying build/lib/apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n","copying build/lib/apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n","copying build/lib/apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n","copying build/lib/apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n","creating build/bdist.linux-x86_64/egg/apex/contrib/test/optimizers\n","copying build/lib/apex/contrib/test/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/optimizers\n","copying build/lib/apex/contrib/test/optimizers/test_dist_adam.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/optimizers\n","creating build/bdist.linux-x86_64/egg/apex/contrib/test/peer_memory\n","copying build/lib/apex/contrib/test/peer_memory/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/peer_memory\n","copying build/lib/apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/peer_memory\n","creating build/bdist.linux-x86_64/egg/apex/contrib/test/transducer\n","copying build/lib/apex/contrib/test/transducer/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/transducer\n","copying build/lib/apex/contrib/test/transducer/test_transducer_joint.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/transducer\n","copying build/lib/apex/contrib/test/transducer/test_transducer_loss.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/transducer\n","creating build/bdist.linux-x86_64/egg/apex/contrib/test/xentropy\n","copying build/lib/apex/contrib/test/xentropy/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/xentropy\n","copying build/lib/apex/contrib/test/xentropy/test_label_smoothing.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/xentropy\n","creating build/bdist.linux-x86_64/egg/apex/contrib/transducer\n","copying build/lib/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/transducer\n","copying build/lib/apex/contrib/transducer/_transducer_ref.py -> build/bdist.linux-x86_64/egg/apex/contrib/transducer\n","copying build/lib/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/egg/apex/contrib/transducer\n","creating build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n","copying build/lib/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n","copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n","creating build/bdist.linux-x86_64/egg/apex/fp16_utils\n","copying build/lib/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n","copying build/lib/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n","copying build/lib/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n","copying build/lib/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n","creating build/bdist.linux-x86_64/egg/apex/fused_dense\n","copying build/lib/apex/fused_dense/__init__.py -> build/bdist.linux-x86_64/egg/apex/fused_dense\n","copying build/lib/apex/fused_dense/fused_dense.py -> build/bdist.linux-x86_64/egg/apex/fused_dense\n","creating build/bdist.linux-x86_64/egg/apex/mlp\n","copying build/lib/apex/mlp/__init__.py -> build/bdist.linux-x86_64/egg/apex/mlp\n","copying build/lib/apex/mlp/mlp.py -> build/bdist.linux-x86_64/egg/apex/mlp\n","creating build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n","copying build/lib/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n","copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n","creating build/bdist.linux-x86_64/egg/apex/normalization\n","copying build/lib/apex/normalization/__init__.py -> build/bdist.linux-x86_64/egg/apex/normalization\n","copying build/lib/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/egg/apex/normalization\n","creating build/bdist.linux-x86_64/egg/apex/optimizers\n","copying build/lib/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n","copying build/lib/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n","copying build/lib/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n","copying build/lib/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n","copying build/lib/apex/optimizers/fused_mixed_precision_lamb.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n","copying build/lib/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n","copying build/lib/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n","creating build/bdist.linux-x86_64/egg/apex/parallel\n","copying build/lib/apex/parallel/LARC.py -> build/bdist.linux-x86_64/egg/apex/parallel\n","copying build/lib/apex/parallel/__init__.py -> build/bdist.linux-x86_64/egg/apex/parallel\n","copying build/lib/apex/parallel/distributed.py -> build/bdist.linux-x86_64/egg/apex/parallel\n","copying build/lib/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/egg/apex/parallel\n","copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n","copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n","copying build/lib/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n","copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n","creating build/bdist.linux-x86_64/egg/apex/transformer\n","copying build/lib/apex/transformer/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer\n","copying build/lib/apex/transformer/enums.py -> build/bdist.linux-x86_64/egg/apex/transformer\n","copying build/lib/apex/transformer/log_util.py -> build/bdist.linux-x86_64/egg/apex/transformer\n","copying build/lib/apex/transformer/microbatches.py -> build/bdist.linux-x86_64/egg/apex/transformer\n","copying build/lib/apex/transformer/parallel_state.py -> build/bdist.linux-x86_64/egg/apex/transformer\n","copying build/lib/apex/transformer/utils.py -> build/bdist.linux-x86_64/egg/apex/transformer\n","creating build/bdist.linux-x86_64/egg/apex/transformer/_data\n","copying build/lib/apex/transformer/_data/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/_data\n","copying build/lib/apex/transformer/_data/_batchsampler.py -> build/bdist.linux-x86_64/egg/apex/transformer/_data\n","creating build/bdist.linux-x86_64/egg/apex/transformer/amp\n","copying build/lib/apex/transformer/amp/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/amp\n","copying build/lib/apex/transformer/amp/grad_scaler.py -> build/bdist.linux-x86_64/egg/apex/transformer/amp\n","creating build/bdist.linux-x86_64/egg/apex/transformer/functional\n","copying build/lib/apex/transformer/functional/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/functional\n","copying build/lib/apex/transformer/functional/fused_softmax.py -> build/bdist.linux-x86_64/egg/apex/transformer/functional\n","creating build/bdist.linux-x86_64/egg/apex/transformer/layers\n","copying build/lib/apex/transformer/layers/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/layers\n","copying build/lib/apex/transformer/layers/layer_norm.py -> build/bdist.linux-x86_64/egg/apex/transformer/layers\n","creating build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel\n","copying build/lib/apex/transformer/pipeline_parallel/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel\n","copying build/lib/apex/transformer/pipeline_parallel/_timers.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel\n","copying build/lib/apex/transformer/pipeline_parallel/p2p_communication.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel\n","copying build/lib/apex/transformer/pipeline_parallel/utils.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel\n","creating build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n","copying build/lib/apex/transformer/pipeline_parallel/schedules/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n","copying build/lib/apex/transformer/pipeline_parallel/schedules/common.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n","copying build/lib/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n","copying build/lib/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n","copying build/lib/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n","creating build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n","copying build/lib/apex/transformer/tensor_parallel/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n","copying build/lib/apex/transformer/tensor_parallel/cross_entropy.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n","copying build/lib/apex/transformer/tensor_parallel/data.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n","copying build/lib/apex/transformer/tensor_parallel/layers.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n","copying build/lib/apex/transformer/tensor_parallel/mappings.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n","copying build/lib/apex/transformer/tensor_parallel/memory.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n","copying build/lib/apex/transformer/tensor_parallel/random.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n","copying build/lib/apex/transformer/tensor_parallel/utils.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n","creating build/bdist.linux-x86_64/egg/apex/transformer/testing\n","copying build/lib/apex/transformer/testing/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n","copying build/lib/apex/transformer/testing/arguments.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n","copying build/lib/apex/transformer/testing/commons.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n","copying build/lib/apex/transformer/testing/distributed_test_base.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n","copying build/lib/apex/transformer/testing/global_vars.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n","copying build/lib/apex/transformer/testing/standalone_bert.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n","copying build/lib/apex/transformer/testing/standalone_gpt.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n","copying build/lib/apex/transformer/testing/standalone_transformer_lm.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n","byte-compiling build/bdist.linux-x86_64/egg/apex/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/_autocast_utils.py to _autocast_utils.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/RNNBackend.py to RNNBackend.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/cells.py to cells.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/models.py to models.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__version__.py to __version__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_amp_state.py to _amp_state.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_initialize.py to _initialize.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_process_optimizer.py to _process_optimizer.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/amp.py to amp.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/compat.py to compat.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/frontend.py to frontend.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/handle.py to handle.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/opt.py to opt.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/rnn_compat.py to rnn_compat.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/scaler.py to scaler.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/utils.py to utils.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/wrap.py to wrap.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/bottleneck/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/bottleneck/bottleneck.py to bottleneck.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/bottleneck/halo_exchangers.py to halo_exchangers.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/bottleneck/test.py to test.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/clip_grad/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/clip_grad/clip_grad.py to clip_grad.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/conv_bias_relu/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/conv_bias_relu/conv_bias_relu.py to conv_bias_relu.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/cudnn_gbn/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/cudnn_gbn/batch_norm.py to batch_norm.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/fmha/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/fmha/fmha.py to fmha.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/focal_loss/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/focal_loss/focal_loss.py to focal_loss.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/groupbn/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/index_mul_2d/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/index_mul_2d/index_mul_2d.py to index_mul_2d.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/layer_norm/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/layer_norm/layer_norm.py to layer_norm.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/peer_memory/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/peer_memory/peer_halo_exchanger_1d.py to peer_halo_exchanger_1d.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/peer_memory/peer_memory.py to peer_memory.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/asp.py to asp.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_lib.py to permutation_lib.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py to call_permutation_search_kernels.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels/channel_swap.py to channel_swap.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py to exhaustive_search.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py to permutation_utilities.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/bottleneck/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/bottleneck/test_bottleneck_module.py to test_bottleneck_module.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/clip_grad/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/clip_grad/test_clip_grad.py to test_clip_grad.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/conv_bias_relu/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py to test_conv_bias_relu.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/cudnn_gbn/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py to test_cudnn_gbn_with_two_gpus.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/fmha/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/fmha/test_fmha.py to test_fmha.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/focal_loss/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/focal_loss/test_focal_loss.py to test_focal_loss.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/index_mul_2d/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/index_mul_2d/test_index_mul_2d.py to test_index_mul_2d.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/layer_norm/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/layer_norm/test_fast_layer_norm.py to test_fast_layer_norm.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py to test_encdec_multihead_attn.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py to test_encdec_multihead_attn_norm_add.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py to test_fast_self_multihead_attn_bias.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/test_mha_fused_softmax.py to test_mha_fused_softmax.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/test_self_multihead_attn.py to test_self_multihead_attn.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py to test_self_multihead_attn_norm_add.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/optimizers/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/optimizers/test_dist_adam.py to test_dist_adam.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/peer_memory/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py to test_peer_halo_exchange_module.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/transducer/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/transducer/test_transducer_joint.py to test_transducer_joint.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/transducer/test_transducer_loss.py to test_transducer_loss.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/xentropy/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/xentropy/test_label_smoothing.py to test_label_smoothing.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/transducer/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/transducer/_transducer_ref.py to _transducer_ref.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/transducer/transducer.py to transducer.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/xentropy/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16util.py to fp16util.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/fused_dense/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/fused_dense/fused_dense.py to fused_dense.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/mlp/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/mlp/mlp.py to mlp.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/multi_tensor_apply/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_adam.py to fused_adam.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_lamb.py to fused_lamb.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_mixed_precision_lamb.py to fused_mixed_precision_lamb.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_novograd.py to fused_novograd.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_sgd.py to fused_sgd.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/LARC.py to LARC.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/distributed.py to distributed.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/multiproc.py to multiproc.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/enums.py to enums.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/log_util.py to log_util.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/microbatches.py to microbatches.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/parallel_state.py to parallel_state.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/utils.py to utils.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/_data/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/_data/_batchsampler.py to _batchsampler.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/amp/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/amp/grad_scaler.py to grad_scaler.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/functional/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/functional/fused_softmax.py to fused_softmax.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/layers/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/layers/layer_norm.py to layer_norm.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/_timers.py to _timers.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/p2p_communication.py to p2p_communication.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/utils.py to utils.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules/common.py to common.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py to fwd_bwd_no_pipelining.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py to fwd_bwd_pipelining_with_interleaving.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py to fwd_bwd_pipelining_without_interleaving.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/cross_entropy.py to cross_entropy.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/data.py to data.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/layers.py to layers.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/mappings.py to mappings.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/memory.py to memory.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/random.py to random.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/utils.py to utils.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/arguments.py to arguments.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/commons.py to commons.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/distributed_test_base.py to distributed_test_base.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/global_vars.py to global_vars.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/standalone_bert.py to standalone_bert.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/standalone_gpt.py to standalone_gpt.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/standalone_transformer_lm.py to standalone_transformer_lm.cpython-37.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying apex.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying apex.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying apex.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying apex.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","zip_safe flag not set; analyzing archive contents...\n","creating 'dist/apex-0.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing apex-0.1-py3.7.egg\n","Removing /usr/local/lib/python3.7/dist-packages/apex-0.1-py3.7.egg\n","Copying apex-0.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n","apex 0.1 is already the active version in easy-install.pth\n","\n","Installed /usr/local/lib/python3.7/dist-packages/apex-0.1-py3.7.egg\n","Processing dependencies for apex==0.1\n","Finished processing dependencies for apex==0.1\n"]}]},{"cell_type":"code","source":["!pip install -qr /content/drive/MyDrive/Code/ViT-pytorch-main/requirements.txt"],"metadata":{"id":"L3wQCe3t_0J8"},"id":"L3wQCe3t_0J8","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","path=\"/content/drive/MyDrive/Code/ViT-pytorch-main\"\n","os.chdir(path)\n","os.listdir(path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TWFCcDZt7Ryu","executionInfo":{"status":"ok","timestamp":1664211188139,"user_tz":-120,"elapsed":13,"user":{"displayName":"Yueying CAO","userId":"04257612248168992935"}},"outputId":"a4023bb9-e54f-4fe5-f66a-ad26a427de3f"},"id":"TWFCcDZt7Ryu","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['LICENSE',\n"," '.gitignore',\n"," 'visualize_attention_map.ipynb',\n"," 'README.md',\n"," 'requirements.txt',\n"," 'ngrok',\n"," 'img',\n"," 'data',\n"," 'logs',\n"," 'models',\n"," 'output',\n"," 'utils',\n"," 'checkpoint',\n"," '.ipynb_checkpoints',\n"," 'ViT-B_16-224.ipynb',\n"," 'apex']"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","execution_count":null,"id":"f2604b88","metadata":{"id":"f2604b88"},"outputs":[],"source":["# coding=utf-8\n","from __future__ import absolute_import, division, print_function\n","\n","import logging\n","import argparse\n","import os\n","import random\n","import numpy as np\n","\n","from datetime import timedelta\n","\n","import torch\n","import torch.distributed as dist\n","\n","from tqdm import tqdm\n","from torch.utils.tensorboard import SummaryWriter\n","from apex import amp\n","from apex.parallel import DistributedDataParallel as DDP\n","\n","from models.modeling import VisionTransformer, CONFIGS\n","from utils.scheduler import WarmupLinearSchedule, WarmupCosineSchedule\n","from utils.data_utils import get_loader\n","from utils.dist_util import get_world_size\n","import sys\n","sys.argv = ['train.py']"]},{"cell_type":"code","execution_count":null,"id":"f8c21e31","metadata":{"id":"f8c21e31"},"outputs":[],"source":["logger = logging.getLogger(__name__)"]},{"cell_type":"code","execution_count":null,"id":"92ef5443","metadata":{"id":"92ef5443"},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"cell_type":"code","execution_count":null,"id":"2eda16b5","metadata":{"id":"2eda16b5"},"outputs":[],"source":["def simple_accuracy(preds, labels):\n","    return (preds == labels).mean()"]},{"cell_type":"code","execution_count":null,"id":"276e98ae","metadata":{"id":"276e98ae"},"outputs":[],"source":["def save_model(args, model):\n","    model_to_save = model.module if hasattr(model, 'module') else model\n","    model_checkpoint = os.path.join(args.output_dir, \"%s_checkpoint.bin\" % args.name)\n","    torch.save(model_to_save.state_dict(), model_checkpoint)\n","    logger.info(\"Saved model checkpoint to [DIR: %s]\", args.output_dir)"]},{"cell_type":"code","execution_count":null,"id":"2ac48a04","metadata":{"id":"2ac48a04"},"outputs":[],"source":["def setup(args):\n","    # Prepare model\n","    config = CONFIGS[args.model_type]\n","\n","    num_classes = 10 if args.dataset == \"cifar10\" else 100\n","\n","    model = VisionTransformer(config, args.img_size, zero_head=True, num_classes=num_classes)\n","    model.load_from(np.load(args.pretrained_dir))\n","    model.to(args.device)\n","    num_params = count_parameters(model)\n","\n","    logger.info(\"{}\".format(config))\n","    logger.info(\"Training parameters %s\", args)\n","    logger.info(\"Total Parameter: \\t%2.1fM\" % num_params)\n","    print(num_params)\n","    return args, model"]},{"cell_type":"code","execution_count":null,"id":"dbc1bdbd","metadata":{"id":"dbc1bdbd"},"outputs":[],"source":["def count_parameters(model):\n","    params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    return params/1000000"]},{"cell_type":"code","execution_count":null,"id":"8421f501","metadata":{"id":"8421f501"},"outputs":[],"source":["def set_seed(args):\n","    random.seed(args.seed)\n","    np.random.seed(args.seed)\n","    torch.manual_seed(args.seed)\n","    if args.n_gpu > 0:\n","        torch.cuda.manual_seed_all(args.seed)"]},{"cell_type":"code","execution_count":null,"id":"ad2e4616","metadata":{"id":"ad2e4616"},"outputs":[],"source":["def valid(args, model, writer, test_loader, global_step):\n","    # Validation!\n","    eval_losses = AverageMeter()\n","\n","    logger.info(\"***** Running Validation *****\")\n","    logger.info(\"  Num steps = %d\", len(test_loader))\n","    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n","\n","    model.eval()\n","    all_preds, all_label = [], []\n","    epoch_iterator = tqdm(test_loader,\n","                          desc=\"Validating... (loss=X.X)\",\n","                          bar_format=\"{l_bar}{r_bar}\",\n","                          dynamic_ncols=True,\n","                          disable=args.local_rank not in [-1, 0])\n","    loss_fct = torch.nn.CrossEntropyLoss()\n","    for step, batch in enumerate(epoch_iterator):\n","        batch = tuple(t.to(args.device) for t in batch)\n","        x, y = batch\n","        with torch.no_grad():\n","            logits = model(x)[0]\n","\n","            eval_loss = loss_fct(logits, y)\n","            eval_losses.update(eval_loss.item())\n","\n","            preds = torch.argmax(logits, dim=-1)\n","\n","        if len(all_preds) == 0:\n","            all_preds.append(preds.detach().cpu().numpy())\n","            all_label.append(y.detach().cpu().numpy())\n","        else:\n","            all_preds[0] = np.append(\n","                all_preds[0], preds.detach().cpu().numpy(), axis=0\n","            )\n","            all_label[0] = np.append(\n","                all_label[0], y.detach().cpu().numpy(), axis=0\n","            )\n","        epoch_iterator.set_description(\"Validating... (loss=%2.5f)\" % eval_losses.val)\n","\n","    all_preds, all_label = all_preds[0], all_label[0]\n","    accuracy = simple_accuracy(all_preds, all_label)\n","\n","    logger.info(\"\\n\")\n","    logger.info(\"Validation Results\")\n","    logger.info(\"Global Steps: %d\" % global_step)\n","    logger.info(\"Valid Loss: %2.5f\" % eval_losses.avg)\n","    logger.info(\"Valid Accuracy: %2.5f\" % accuracy)\n","\n","    writer.add_scalar(\"test/accuracy\", scalar_value=accuracy, global_step=global_step)\n","    return accuracy"]},{"cell_type":"code","execution_count":null,"id":"3b626e69","metadata":{"id":"3b626e69"},"outputs":[],"source":["def train(args, model):\n","    \"\"\" Train the model \"\"\"\n","    if args.local_rank in [-1, 0]:\n","        os.makedirs(args.output_dir, exist_ok=True)\n","        writer = SummaryWriter(log_dir=os.path.join(\"logs\", args.name))\n","\n","    args.train_batch_size = args.train_batch_size // args.gradient_accumulation_steps\n","\n","    # Prepare dataset\n","    train_loader, test_loader = get_loader(args)\n","\n","    # Prepare optimizer and scheduler\n","    optimizer = torch.optim.SGD(model.parameters(),\n","                                lr=args.learning_rate,\n","                                momentum=0.9,\n","                                weight_decay=args.weight_decay)\n","    t_total = args.num_steps\n","    if args.decay_type == \"cosine\":\n","        scheduler = WarmupCosineSchedule(optimizer, warmup_steps=args.warmup_steps, t_total=t_total)\n","    else:\n","        scheduler = WarmupLinearSchedule(optimizer, warmup_steps=args.warmup_steps, t_total=t_total)\n","\n","    if args.fp16:\n","        model, optimizer = amp.initialize(models=model,\n","                                          optimizers=optimizer,\n","                                          opt_level=args.fp16_opt_level)\n","        amp._amp_state.loss_scalers[0]._loss_scale = 2**20\n","\n","    # Distributed training\n","    if args.local_rank != -1:\n","        model = DDP(model, message_size=250000000, gradient_predivide_factor=get_world_size())\n","\n","    # Train!\n","    logger.info(\"***** Running training *****\")\n","    logger.info(\"  Total optimization steps = %d\", args.num_steps)\n","    logger.info(\"  Instantaneous batch size per GPU = %d\", args.train_batch_size)\n","    logger.info(\"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n","                args.train_batch_size * args.gradient_accumulation_steps * (\n","                    torch.distributed.get_world_size() if args.local_rank != -1 else 1))\n","    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n","\n","    model.zero_grad()\n","    set_seed(args)  # Added here for reproducibility (even between python 2 and 3)\n","    losses = AverageMeter()\n","    global_step, best_acc = 0, 0\n","    while True:\n","        model.train()\n","        epoch_iterator = tqdm(train_loader,\n","                              desc=\"Training (X / X Steps) (loss=X.X)\",\n","                              bar_format=\"{l_bar}{r_bar}\",\n","                              dynamic_ncols=True,\n","                              disable=args.local_rank not in [-1, 0])                    \n","        for step, batch in enumerate(epoch_iterator):\n","            batch = tuple(t.to(args.device) for t in batch)\n","            x, y = batch\n","            loss = model(x, y)\n","\n","            if args.gradient_accumulation_steps > 1:\n","                loss = loss / args.gradient_accumulation_steps\n","            if args.fp16:\n","                with amp.scale_loss(loss, optimizer) as scaled_loss:\n","                    scaled_loss.backward()\n","            else:\n","                loss.backward()\n","\n","            # if (step + 1) % args.gradient_accumulation_steps == 0:\n","            if step % args.gradient_accumulation_steps == 0:\n","                losses.update(loss.item()*args.gradient_accumulation_steps)\n","                if args.fp16:\n","                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n","                else:\n","                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n","                scheduler.step()\n","                optimizer.step()\n","                optimizer.zero_grad()\n","                global_step += 1\n","\n","                epoch_iterator.set_description(\n","                    \"Training (%d / %d Steps) (loss=%2.5f)\" % (global_step, t_total, losses.val)\n","                )\n","                if args.local_rank in [-1, 0]:\n","                    writer.add_scalar(\"train/loss\", scalar_value=losses.val, global_step=global_step)\n","                    writer.add_scalar(\"train/lr\", scalar_value=scheduler.get_lr()[0], global_step=global_step)\n","                if global_step % args.eval_every == 0 and args.local_rank in [-1, 0]:\n","                    accuracy = valid(args, model, writer, test_loader, global_step)\n","                    if best_acc < accuracy:\n","                        save_model(args, model)\n","                        best_acc = accuracy\n","                    model.train()\n","\n","                if global_step % t_total == 0:\n","                    break\n","        losses.reset()\n","        if global_step % t_total == 0:\n","            break\n","\n","    if args.local_rank in [-1, 0]:\n","        writer.close()\n","    logger.info(\"Best Accuracy: \\t%f\" % best_acc)\n","    logger.info(\"End Training!\")\n"]},{"cell_type":"code","execution_count":29,"id":"0b73b3df","metadata":{"id":"0b73b3df","executionInfo":{"status":"ok","timestamp":1664211883193,"user_tz":-120,"elapsed":308,"user":{"displayName":"Yueying CAO","userId":"04257612248168992935"}}},"outputs":[],"source":["def main():\n","    parser = argparse.ArgumentParser()\n","    # Required parameters\n","    # parser.add_argument(\"--name\", required=True, default=\"ants-bees\",\n","    #                     help=\"Name of this run. Used for monitoring.\")\n","    parser.add_argument(\"--name\", default=\"ants-bees\",\n","                        help=\"Name of this run. Used for monitoring.\")\n","    parser.add_argument(\"--dataset\", choices=[\"cifar10\", \"cifar100\"], default=\"ants-bees\",\n","                        help=\"Which downstream task.\")\n","    parser.add_argument(\"--model_type\", choices=[\"ViT-B_16\", \"ViT-B_32\", \"ViT-L_16\", \"ViT-L_32\", \"ViT-H_14\", \"R50-ViT-B_16\"],\n","                        default=\"ViT-B_32\",\n","                        help=\"Which variant to use.\")\n","    parser.add_argument(\"--pretrained_dir\", type=str, default=\"/content/drive/MyDrive/Code/ViT-pytorch-main/checkpoint/ViT-B_32.npz\",\n","                        help=\"Where to search for pretrained ViT models.\")\n","    parser.add_argument(\"--output_dir\", default=\"output\", type=str,\n","                        help=\"The output directory where checkpoints will be written.\")\n","\n","    parser.add_argument(\"--img_size\", default=224, type=int,\n","                        help=\"Resolution size\")\n","    parser.add_argument(\"--train_batch_size\", default=512, type=int,\n","                        help=\"Total batch size for training.\")\n","    parser.add_argument(\"--eval_batch_size\", default=64, type=int,\n","                        help=\"Total batch size for eval.\")\n","    parser.add_argument(\"--eval_every\", default=50, type=int,\n","                        help=\"Run prediction on validation set every so many steps.\"\n","                             \"Will always run one evaluation at the end of training.\")\n","\n","    parser.add_argument(\"--learning_rate\", default=3e-2, type=float,\n","                        help=\"The initial learning rate for SGD.\")\n","    parser.add_argument(\"--weight_decay\", default=0, type=float,\n","                        help=\"Weight deay if we apply some.\")\n","    parser.add_argument(\"--num_steps\", default=1000, type=int,\n","                        help=\"Total number of training epochs to perform.\")\n","    parser.add_argument(\"--decay_type\", choices=[\"cosine\", \"linear\"], default=\"cosine\",\n","                        help=\"How to decay the learning rate.\")\n","    parser.add_argument(\"--warmup_steps\", default=100, type=int,\n","                        help=\"Step of training to perform learning rate warmup for.\")\n","    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float,\n","                        help=\"Max gradient norm.\")\n","\n","    parser.add_argument(\"--local_rank\", type=int, default=-1,\n","                        help=\"local_rank for distributed training on gpus\")\n","    parser.add_argument('--seed', type=int, default=42,\n","                        help=\"random seed for initialization\")\n","    parser.add_argument('--gradient_accumulation_steps', type=int, default=30,\n","                        help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n","    parser.add_argument('--fp16', action='store_true',\n","                        help=\"Whether to use 16-bit float precision instead of 32-bit\")\n","    parser.add_argument('--fp16_opt_level', type=str, default='O2',\n","                        help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n","                             \"See details at https://nvidia.github.io/apex/amp.html\")\n","    parser.add_argument('--loss_scale', type=float, default=0,\n","                        help=\"Loss scaling to improve fp16 numeric stability. Only used when fp16 set to True.\\n\"\n","                             \"0 (default value): dynamic loss scaling.\\n\"\n","                             \"Positive power of 2: static loss scaling value.\\n\")\n","    args = parser.parse_args()\n","\n","    # Setup CUDA, GPU & distributed training\n","    if args.local_rank == -1:\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        args.n_gpu = torch.cuda.device_count()\n","    else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n","        torch.cuda.set_device(args.local_rank)\n","        device = torch.device(\"cuda\", args.local_rank)\n","        torch.distributed.init_process_group(backend='nccl',\n","                                             timeout=timedelta(minutes=60))\n","        args.n_gpu = 1\n","    args.device = device\n","\n","    # Setup logging\n","    logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n","                        datefmt='%m/%d/%Y %H:%M:%S',\n","                        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN)\n","    logger.warning(\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\" %\n","                   (args.local_rank, args.device, args.n_gpu, bool(args.local_rank != -1), args.fp16))\n","\n","    # Set seed\n","    set_seed(args)\n","\n","    # Model & Tokenizer Setup\n","    args, model = setup(args)\n","\n","    # Training\n","    train(args, model)"]},{"cell_type":"markdown","source":["Download and unzip [ngrok](https://ngrok.com)."],"metadata":{"id":"RAW1TKELM9-o"},"id":"RAW1TKELM9-o"},{"cell_type":"code","source":["# Get TensorBoard running in the background. \n","LOG_DIR = '/content/drive/MyDrive/Code/ViT-pytorch-main/logs/ants-bees'\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")\n","\n","# Make sure we're able to connect to the TensorBoard service.\n","! curl http://localhost:6006"],"metadata":{"id":"BaVe4ZU0NFD8","executionInfo":{"status":"ok","timestamp":1664211194707,"user_tz":-120,"elapsed":22,"user":{"displayName":"Yueying CAO","userId":"04257612248168992935"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"26ad47a9-8a52-423c-ceb9-e02a9f8a6187"},"id":"BaVe4ZU0NFD8","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["curl: (7) Failed to connect to localhost port 6006: Connection refused\n"]}]},{"cell_type":"code","source":["# Download and unzip\n","! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1\n","! unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1\n","\n","# Launch ngrok background process and retrieve public url.\n","get_ipython().system_raw('./ngrok http 6006 &')\n","\n","! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zJST3sDmgoR9","executionInfo":{"status":"ok","timestamp":1664211243373,"user_tz":-120,"elapsed":48683,"user":{"displayName":"Yueying CAO","userId":"04257612248168992935"}},"outputId":"06f3dc40-d42e-4f94-ac09-f64c42dbf456"},"id":"zJST3sDmgoR9","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/usr/lib/python3.7/json/__init__.py\", line 296, in load\n","    parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n","  File \"/usr/lib/python3.7/json/__init__.py\", line 348, in loads\n","    return _default_decoder.decode(s)\n","  File \"/usr/lib/python3.7/json/decoder.py\", line 337, in decode\n","    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n","  File \"/usr/lib/python3.7/json/decoder.py\", line 355, in raw_decode\n","    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n","json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"VmKxSxGtOsaD"},"id":"VmKxSxGtOsaD","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":30,"id":"db687c14","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"db687c14","outputId":"629438f1-7b0f-4e2f-90e5-645484d73cab","executionInfo":{"status":"ok","timestamp":1664215142657,"user_tz":-120,"elapsed":1141476,"user":{"displayName":"Yueying CAO","userId":"04257612248168992935"}}},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:__main__:Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["load_pretrained: grid-size from 12 to 7\n","87.532132\n","my data!\n","{'ants': 0, 'bees': 1}\n","244\n","****************************************************************************************************\n","153\n"]},{"output_type":"stream","name":"stderr","text":["Training (1 / 1000 Steps) (loss=4.60517): 100%|| 15/15 [00:03<00:00,  4.91it/s]\n","Training (2 / 1000 Steps) (loss=4.60420): 100%|| 15/15 [00:02<00:00,  5.12it/s]\n","Training (3 / 1000 Steps) (loss=4.59654): 100%|| 15/15 [00:02<00:00,  5.20it/s]\n","Training (4 / 1000 Steps) (loss=4.57524): 100%|| 15/15 [00:02<00:00,  5.06it/s]\n","Training (5 / 1000 Steps) (loss=4.54314): 100%|| 15/15 [00:02<00:00,  5.01it/s]\n","Training (6 / 1000 Steps) (loss=4.49519): 100%|| 15/15 [00:03<00:00,  4.56it/s]\n","Training (7 / 1000 Steps) (loss=4.39852): 100%|| 15/15 [00:02<00:00,  5.12it/s]\n","Training (8 / 1000 Steps) (loss=4.29560): 100%|| 15/15 [00:02<00:00,  5.19it/s]\n","Training (9 / 1000 Steps) (loss=4.12512): 100%|| 15/15 [00:03<00:00,  4.52it/s]\n","Training (10 / 1000 Steps) (loss=4.03005): 100%|| 15/15 [00:03<00:00,  4.11it/s]\n","Training (11 / 1000 Steps) (loss=3.81499): 100%|| 15/15 [00:02<00:00,  5.14it/s]\n","Training (12 / 1000 Steps) (loss=3.60160): 100%|| 15/15 [00:02<00:00,  5.12it/s]\n","Training (13 / 1000 Steps) (loss=3.44405): 100%|| 15/15 [00:02<00:00,  5.17it/s]\n","Training (14 / 1000 Steps) (loss=2.95363): 100%|| 15/15 [00:02<00:00,  5.01it/s]\n","Training (15 / 1000 Steps) (loss=2.53601): 100%|| 15/15 [00:02<00:00,  5.21it/s]\n","Training (16 / 1000 Steps) (loss=2.38478): 100%|| 15/15 [00:02<00:00,  5.08it/s]\n","Training (17 / 1000 Steps) (loss=1.91910): 100%|| 15/15 [00:02<00:00,  5.09it/s]\n","Training (18 / 1000 Steps) (loss=1.66861): 100%|| 15/15 [00:03<00:00,  4.98it/s]\n","Training (19 / 1000 Steps) (loss=1.15930): 100%|| 15/15 [00:02<00:00,  5.01it/s]\n","Training (20 / 1000 Steps) (loss=1.25427): 100%|| 15/15 [00:02<00:00,  5.09it/s]\n","Training (21 / 1000 Steps) (loss=0.85002): 100%|| 15/15 [00:02<00:00,  5.04it/s]\n","Training (22 / 1000 Steps) (loss=0.39219): 100%|| 15/15 [00:03<00:00,  4.98it/s]\n","Training (23 / 1000 Steps) (loss=0.35762): 100%|| 15/15 [00:03<00:00,  4.89it/s]\n","Training (24 / 1000 Steps) (loss=0.40806): 100%|| 15/15 [00:03<00:00,  4.67it/s]\n","Training (25 / 1000 Steps) (loss=0.37626): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (26 / 1000 Steps) (loss=0.31934): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (27 / 1000 Steps) (loss=0.33593): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (28 / 1000 Steps) (loss=0.05198): 100%|| 15/15 [00:02<00:00,  5.04it/s]\n","Training (29 / 1000 Steps) (loss=0.01566): 100%|| 15/15 [00:03<00:00,  4.98it/s]\n","Training (30 / 1000 Steps) (loss=0.05449): 100%|| 15/15 [00:03<00:00,  4.91it/s]\n","Training (31 / 1000 Steps) (loss=0.26821): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (32 / 1000 Steps) (loss=0.03886): 100%|| 15/15 [00:02<00:00,  5.09it/s]\n","Training (33 / 1000 Steps) (loss=0.22526): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (34 / 1000 Steps) (loss=0.41919): 100%|| 15/15 [00:03<00:00,  4.93it/s]\n","Training (35 / 1000 Steps) (loss=0.11435): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (36 / 1000 Steps) (loss=0.00444): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (37 / 1000 Steps) (loss=0.26410): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (38 / 1000 Steps) (loss=0.34393): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (39 / 1000 Steps) (loss=0.02644): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (40 / 1000 Steps) (loss=0.00657): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (41 / 1000 Steps) (loss=0.01717): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (42 / 1000 Steps) (loss=0.00102): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (43 / 1000 Steps) (loss=0.03591): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (44 / 1000 Steps) (loss=0.00090): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (45 / 1000 Steps) (loss=0.00387): 100%|| 15/15 [00:03<00:00,  4.61it/s]\n","Training (46 / 1000 Steps) (loss=0.09582): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (47 / 1000 Steps) (loss=0.02051): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (48 / 1000 Steps) (loss=0.04753): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (49 / 1000 Steps) (loss=0.01650): 100%|| 15/15 [00:03<00:00,  4.63it/s]\n","Training (50 / 1000 Steps) (loss=0.00131):   0%|| 0/15 [00:00<?, ?it/s]\n","Validating... (loss=X.X):   0%|| 0/3 [00:00<?, ?it/s]\u001b[A\n","Validating... (loss=0.14224):   0%|| 0/3 [00:17<?, ?it/s]\u001b[A\n","Validating... (loss=0.14224):  33%|| 1/3 [00:17<00:35, 17.94s/it]\u001b[A\n","Validating... (loss=0.13638):  33%|| 1/3 [00:18<00:35, 17.94s/it]\u001b[A\n","Validating... (loss=0.13638):  67%|| 2/3 [00:18<00:07,  7.50s/it]\u001b[A\n","Validating... (loss=0.13597): 100%|| 3/3 [00:18<00:00,  6.11s/it]\n","Training (50 / 1000 Steps) (loss=0.00131): 100%|| 15/15 [00:31<00:00,  2.09s/it]\n","Training (51 / 1000 Steps) (loss=0.00332): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (52 / 1000 Steps) (loss=0.17727): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (53 / 1000 Steps) (loss=0.00908): 100%|| 15/15 [00:03<00:00,  4.03it/s]\n","Training (54 / 1000 Steps) (loss=0.01872): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (55 / 1000 Steps) (loss=0.00151): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (56 / 1000 Steps) (loss=0.00739): 100%|| 15/15 [00:03<00:00,  4.52it/s]\n","Training (57 / 1000 Steps) (loss=0.19725): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (58 / 1000 Steps) (loss=0.01691): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (59 / 1000 Steps) (loss=0.13513): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (60 / 1000 Steps) (loss=0.00114): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (61 / 1000 Steps) (loss=0.03141): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (62 / 1000 Steps) (loss=0.00980): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (63 / 1000 Steps) (loss=0.00133): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (64 / 1000 Steps) (loss=0.02536): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (65 / 1000 Steps) (loss=0.00194): 100%|| 15/15 [00:03<00:00,  4.33it/s]\n","Training (66 / 1000 Steps) (loss=0.00060): 100%|| 15/15 [00:03<00:00,  3.92it/s]\n","Training (67 / 1000 Steps) (loss=0.01047): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (68 / 1000 Steps) (loss=0.16394): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (69 / 1000 Steps) (loss=0.01455): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (70 / 1000 Steps) (loss=0.00216): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (71 / 1000 Steps) (loss=0.01013): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (72 / 1000 Steps) (loss=0.09607): 100%|| 15/15 [00:03<00:00,  4.96it/s]\n","Training (73 / 1000 Steps) (loss=0.07048): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (74 / 1000 Steps) (loss=0.00155): 100%|| 15/15 [00:03<00:00,  4.94it/s]\n","Training (75 / 1000 Steps) (loss=0.00214): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (76 / 1000 Steps) (loss=0.00241): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (77 / 1000 Steps) (loss=0.02277): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (78 / 1000 Steps) (loss=0.05003): 100%|| 15/15 [00:03<00:00,  4.61it/s]\n","Training (79 / 1000 Steps) (loss=0.00698): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (80 / 1000 Steps) (loss=0.00192): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (81 / 1000 Steps) (loss=0.05878): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (82 / 1000 Steps) (loss=0.00213): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (83 / 1000 Steps) (loss=0.16349): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (84 / 1000 Steps) (loss=0.01943): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (85 / 1000 Steps) (loss=0.25441): 100%|| 15/15 [00:03<00:00,  4.96it/s]\n","Training (86 / 1000 Steps) (loss=0.04438): 100%|| 15/15 [00:03<00:00,  4.65it/s]\n","Training (87 / 1000 Steps) (loss=0.18303): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (88 / 1000 Steps) (loss=0.00087): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (89 / 1000 Steps) (loss=0.00827): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (90 / 1000 Steps) (loss=0.00281): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (91 / 1000 Steps) (loss=0.00366): 100%|| 15/15 [00:03<00:00,  4.48it/s]\n","Training (92 / 1000 Steps) (loss=0.02465): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (93 / 1000 Steps) (loss=0.00053): 100%|| 15/15 [00:03<00:00,  4.58it/s]\n","Training (94 / 1000 Steps) (loss=0.06085): 100%|| 15/15 [00:03<00:00,  4.68it/s]\n","Training (95 / 1000 Steps) (loss=0.00256): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (96 / 1000 Steps) (loss=0.00084): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (97 / 1000 Steps) (loss=0.00331): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (98 / 1000 Steps) (loss=0.00296): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (99 / 1000 Steps) (loss=0.02684): 100%|| 15/15 [00:03<00:00,  4.91it/s]\n","Training (100 / 1000 Steps) (loss=0.00186):   0%|| 0/15 [00:01<?, ?it/s]\n","Validating... (loss=X.X):   0%|| 0/3 [00:00<?, ?it/s]\u001b[A\n","Validating... (loss=0.21559):   0%|| 0/3 [00:01<?, ?it/s]\u001b[A\n","Validating... (loss=0.21559):  33%|| 1/3 [00:01<00:03,  1.52s/it]\u001b[A\n","Validating... (loss=0.11679):  33%|| 1/3 [00:01<00:03,  1.52s/it]\u001b[A\n","Validating... (loss=0.11679):  67%|| 2/3 [00:01<00:00,  1.29it/s]\u001b[A\n","Validating... (loss=0.06172): 100%|| 3/3 [00:01<00:00,  1.51it/s]\n","Training (100 / 1000 Steps) (loss=0.00186): 100%|| 15/15 [00:05<00:00,  2.87it/s]\n","Training (101 / 1000 Steps) (loss=0.01426): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (102 / 1000 Steps) (loss=0.00193): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (103 / 1000 Steps) (loss=0.00909): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (104 / 1000 Steps) (loss=0.00795): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (105 / 1000 Steps) (loss=0.00024): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (106 / 1000 Steps) (loss=0.01186): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (107 / 1000 Steps) (loss=0.01510): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (108 / 1000 Steps) (loss=0.11446): 100%|| 15/15 [00:03<00:00,  4.68it/s]\n","Training (109 / 1000 Steps) (loss=0.21162): 100%|| 15/15 [00:03<00:00,  4.66it/s]\n","Training (110 / 1000 Steps) (loss=0.00130): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (111 / 1000 Steps) (loss=0.00750): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (112 / 1000 Steps) (loss=0.00371): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (113 / 1000 Steps) (loss=0.00303): 100%|| 15/15 [00:03<00:00,  4.62it/s]\n","Training (114 / 1000 Steps) (loss=0.01357): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (115 / 1000 Steps) (loss=0.02756): 100%|| 15/15 [00:03<00:00,  4.92it/s]\n","Training (116 / 1000 Steps) (loss=0.22035): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (117 / 1000 Steps) (loss=0.00116): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (118 / 1000 Steps) (loss=0.01351): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (119 / 1000 Steps) (loss=0.00905): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (120 / 1000 Steps) (loss=0.01441): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (121 / 1000 Steps) (loss=0.00267): 100%|| 15/15 [00:03<00:00,  4.56it/s]\n","Training (122 / 1000 Steps) (loss=0.00101): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (123 / 1000 Steps) (loss=0.01903): 100%|| 15/15 [00:03<00:00,  4.66it/s]\n","Training (124 / 1000 Steps) (loss=0.02070): 100%|| 15/15 [00:04<00:00,  3.71it/s]\n","Training (125 / 1000 Steps) (loss=0.02502): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (126 / 1000 Steps) (loss=0.00070): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (127 / 1000 Steps) (loss=0.12113): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (128 / 1000 Steps) (loss=0.03378): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (129 / 1000 Steps) (loss=0.02152): 100%|| 15/15 [00:03<00:00,  4.66it/s]\n","Training (130 / 1000 Steps) (loss=0.01185): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (131 / 1000 Steps) (loss=0.04875): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (132 / 1000 Steps) (loss=0.00066): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (133 / 1000 Steps) (loss=0.00363): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (134 / 1000 Steps) (loss=0.00060): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (135 / 1000 Steps) (loss=0.00962): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (136 / 1000 Steps) (loss=0.00068): 100%|| 15/15 [00:03<00:00,  4.95it/s]\n","Training (137 / 1000 Steps) (loss=0.01468): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (138 / 1000 Steps) (loss=0.04190): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (139 / 1000 Steps) (loss=0.04702): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (140 / 1000 Steps) (loss=0.00442): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (141 / 1000 Steps) (loss=0.00088): 100%|| 15/15 [00:03<00:00,  4.91it/s]\n","Training (142 / 1000 Steps) (loss=0.00185): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (143 / 1000 Steps) (loss=0.00041): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (144 / 1000 Steps) (loss=0.00413): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (145 / 1000 Steps) (loss=0.01990): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (146 / 1000 Steps) (loss=0.00913): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (147 / 1000 Steps) (loss=0.00711): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (148 / 1000 Steps) (loss=0.00781): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (149 / 1000 Steps) (loss=0.00368): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (150 / 1000 Steps) (loss=0.01980):   0%|| 0/15 [00:00<?, ?it/s]\n","Validating... (loss=X.X):   0%|| 0/3 [00:00<?, ?it/s]\u001b[A\n","Validating... (loss=0.08616):   0%|| 0/3 [00:01<?, ?it/s]\u001b[A\n","Validating... (loss=0.08616):  33%|| 1/3 [00:01<00:03,  1.75s/it]\u001b[A\n","Validating... (loss=0.13447):  33%|| 1/3 [00:01<00:03,  1.75s/it]\u001b[A\n","Validating... (loss=0.13447):  67%|| 2/3 [00:01<00:00,  1.19it/s]\u001b[A\n","Validating... (loss=0.00387): 100%|| 3/3 [00:02<00:00,  1.38it/s]\n","Training (150 / 1000 Steps) (loss=0.01980): 100%|| 15/15 [00:06<00:00,  2.28it/s]\n","Training (151 / 1000 Steps) (loss=0.00041): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (152 / 1000 Steps) (loss=0.00112): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (153 / 1000 Steps) (loss=0.00201): 100%|| 15/15 [00:03<00:00,  4.16it/s]\n","Training (154 / 1000 Steps) (loss=0.01164): 100%|| 15/15 [00:03<00:00,  4.57it/s]\n","Training (155 / 1000 Steps) (loss=0.00334): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (156 / 1000 Steps) (loss=0.00549): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (157 / 1000 Steps) (loss=0.00203): 100%|| 15/15 [00:03<00:00,  4.68it/s]\n","Training (158 / 1000 Steps) (loss=0.04279): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (159 / 1000 Steps) (loss=0.00431): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (160 / 1000 Steps) (loss=0.00045): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (161 / 1000 Steps) (loss=0.02054): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (162 / 1000 Steps) (loss=0.00080): 100%|| 15/15 [00:03<00:00,  4.94it/s]\n","Training (163 / 1000 Steps) (loss=0.00230): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (164 / 1000 Steps) (loss=0.00146): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (165 / 1000 Steps) (loss=0.00195): 100%|| 15/15 [00:03<00:00,  4.68it/s]\n","Training (166 / 1000 Steps) (loss=0.00207): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (167 / 1000 Steps) (loss=0.00028): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (168 / 1000 Steps) (loss=0.07152): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (169 / 1000 Steps) (loss=0.02654): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (170 / 1000 Steps) (loss=0.04466): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (171 / 1000 Steps) (loss=0.05100): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (172 / 1000 Steps) (loss=0.00028): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (173 / 1000 Steps) (loss=0.19068): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (174 / 1000 Steps) (loss=0.00344): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (175 / 1000 Steps) (loss=0.00196): 100%|| 15/15 [00:03<00:00,  4.63it/s]\n","Training (176 / 1000 Steps) (loss=0.00938): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (177 / 1000 Steps) (loss=0.00017): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (178 / 1000 Steps) (loss=0.00027): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (179 / 1000 Steps) (loss=0.04539): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (180 / 1000 Steps) (loss=0.03051): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (181 / 1000 Steps) (loss=0.00603): 100%|| 15/15 [00:03<00:00,  4.93it/s]\n","Training (182 / 1000 Steps) (loss=0.00349): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (183 / 1000 Steps) (loss=0.00540): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (184 / 1000 Steps) (loss=0.02463): 100%|| 15/15 [00:03<00:00,  4.40it/s]\n","Training (185 / 1000 Steps) (loss=0.01810): 100%|| 15/15 [00:03<00:00,  3.98it/s]\n","Training (186 / 1000 Steps) (loss=0.00118): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (187 / 1000 Steps) (loss=0.02453): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (188 / 1000 Steps) (loss=0.00357): 100%|| 15/15 [00:03<00:00,  4.60it/s]\n","Training (189 / 1000 Steps) (loss=0.00042): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (190 / 1000 Steps) (loss=0.00074): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (191 / 1000 Steps) (loss=0.08831): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (192 / 1000 Steps) (loss=0.00266): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (193 / 1000 Steps) (loss=0.00023): 100%|| 15/15 [00:03<00:00,  4.89it/s]\n","Training (194 / 1000 Steps) (loss=0.04250): 100%|| 15/15 [00:02<00:00,  5.02it/s]\n","Training (195 / 1000 Steps) (loss=0.00044): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (196 / 1000 Steps) (loss=0.00136): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (197 / 1000 Steps) (loss=0.00102): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (198 / 1000 Steps) (loss=0.00085): 100%|| 15/15 [00:03<00:00,  4.68it/s]\n","Training (199 / 1000 Steps) (loss=0.02279): 100%|| 15/15 [00:03<00:00,  4.54it/s]\n","Training (200 / 1000 Steps) (loss=0.00863):   0%|| 0/15 [00:00<?, ?it/s]\n","Validating... (loss=X.X):   0%|| 0/3 [00:00<?, ?it/s]\u001b[A\n","Validating... (loss=0.13277):   0%|| 0/3 [00:01<?, ?it/s]\u001b[A\n","Validating... (loss=0.13277):  33%|| 1/3 [00:01<00:03,  1.65s/it]\u001b[A\n","Validating... (loss=0.43709):  33%|| 1/3 [00:01<00:03,  1.65s/it]\u001b[A\n","Validating... (loss=0.43709):  67%|| 2/3 [00:01<00:00,  1.25it/s]\u001b[A\n","Validating... (loss=0.13761): 100%|| 3/3 [00:02<00:00,  1.45it/s]\n","Training (200 / 1000 Steps) (loss=0.00863): 100%|| 15/15 [00:05<00:00,  2.88it/s]\n","Training (201 / 1000 Steps) (loss=0.00011): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (202 / 1000 Steps) (loss=0.00354): 100%|| 15/15 [00:03<00:00,  4.68it/s]\n","Training (203 / 1000 Steps) (loss=0.13731): 100%|| 15/15 [00:03<00:00,  4.89it/s]\n","Training (204 / 1000 Steps) (loss=0.00041): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (205 / 1000 Steps) (loss=0.00502): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (206 / 1000 Steps) (loss=0.00042): 100%|| 15/15 [00:03<00:00,  4.94it/s]\n","Training (207 / 1000 Steps) (loss=0.00051): 100%|| 15/15 [00:03<00:00,  4.68it/s]\n","Training (208 / 1000 Steps) (loss=0.14837): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (209 / 1000 Steps) (loss=0.00081): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (210 / 1000 Steps) (loss=0.00039): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (211 / 1000 Steps) (loss=0.00072): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (212 / 1000 Steps) (loss=0.13634): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (213 / 1000 Steps) (loss=0.00035): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (214 / 1000 Steps) (loss=0.00141): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (215 / 1000 Steps) (loss=0.01097): 100%|| 15/15 [00:03<00:00,  4.67it/s]\n","Training (216 / 1000 Steps) (loss=0.12641): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (217 / 1000 Steps) (loss=0.00011): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (218 / 1000 Steps) (loss=0.00072): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (219 / 1000 Steps) (loss=0.00140): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (220 / 1000 Steps) (loss=0.00857): 100%|| 15/15 [00:03<00:00,  4.97it/s]\n","Training (221 / 1000 Steps) (loss=0.00029): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (222 / 1000 Steps) (loss=0.00049): 100%|| 15/15 [00:03<00:00,  4.92it/s]\n","Training (223 / 1000 Steps) (loss=0.08824): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (224 / 1000 Steps) (loss=0.00069): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (225 / 1000 Steps) (loss=0.00264): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (226 / 1000 Steps) (loss=0.00019): 100%|| 15/15 [00:03<00:00,  4.65it/s]\n","Training (227 / 1000 Steps) (loss=0.01245): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (228 / 1000 Steps) (loss=0.00009): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (229 / 1000 Steps) (loss=0.00039): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (230 / 1000 Steps) (loss=0.00185): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (231 / 1000 Steps) (loss=0.00532): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (232 / 1000 Steps) (loss=0.00367): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (233 / 1000 Steps) (loss=0.01515): 100%|| 15/15 [00:03<00:00,  4.95it/s]\n","Training (234 / 1000 Steps) (loss=0.00016): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (235 / 1000 Steps) (loss=0.00089): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (236 / 1000 Steps) (loss=0.01214): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (237 / 1000 Steps) (loss=0.00210): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (238 / 1000 Steps) (loss=0.00117): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (239 / 1000 Steps) (loss=0.10516): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (240 / 1000 Steps) (loss=0.00119): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (241 / 1000 Steps) (loss=0.00530): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (242 / 1000 Steps) (loss=0.00223): 100%|| 15/15 [00:03<00:00,  4.52it/s]\n","Training (243 / 1000 Steps) (loss=0.00384): 100%|| 15/15 [00:03<00:00,  3.88it/s]\n","Training (244 / 1000 Steps) (loss=0.00321): 100%|| 15/15 [00:03<00:00,  4.31it/s]\n","Training (245 / 1000 Steps) (loss=0.00727): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (246 / 1000 Steps) (loss=0.00036): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (247 / 1000 Steps) (loss=0.00115): 100%|| 15/15 [00:03<00:00,  4.59it/s]\n","Training (248 / 1000 Steps) (loss=0.00024): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (249 / 1000 Steps) (loss=0.00076): 100%|| 15/15 [00:03<00:00,  4.94it/s]\n","Training (250 / 1000 Steps) (loss=0.00466):   0%|| 0/15 [00:00<?, ?it/s]\n","Validating... (loss=X.X):   0%|| 0/3 [00:00<?, ?it/s]\u001b[A\n","Validating... (loss=0.21368):   0%|| 0/3 [00:01<?, ?it/s]\u001b[A\n","Validating... (loss=0.21368):  33%|| 1/3 [00:01<00:03,  1.63s/it]\u001b[A\n","Validating... (loss=0.13938):  33%|| 1/3 [00:01<00:03,  1.63s/it]\u001b[A\n","Validating... (loss=0.13938):  67%|| 2/3 [00:01<00:00,  1.25it/s]\u001b[A\n","Validating... (loss=0.36973): 100%|| 3/3 [00:02<00:00,  1.45it/s]\n","Training (250 / 1000 Steps) (loss=0.00466): 100%|| 15/15 [00:05<00:00,  2.90it/s]\n","Training (251 / 1000 Steps) (loss=0.00024): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (252 / 1000 Steps) (loss=0.00208): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (253 / 1000 Steps) (loss=0.01459): 100%|| 15/15 [00:03<00:00,  4.95it/s]\n","Training (254 / 1000 Steps) (loss=0.00320): 100%|| 15/15 [00:03<00:00,  4.89it/s]\n","Training (255 / 1000 Steps) (loss=0.01218): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (256 / 1000 Steps) (loss=0.05652): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (257 / 1000 Steps) (loss=0.00027): 100%|| 15/15 [00:03<00:00,  4.60it/s]\n","Training (258 / 1000 Steps) (loss=0.00034): 100%|| 15/15 [00:03<00:00,  4.96it/s]\n","Training (259 / 1000 Steps) (loss=0.00042): 100%|| 15/15 [00:02<00:00,  5.05it/s]\n","Training (260 / 1000 Steps) (loss=0.00013): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (261 / 1000 Steps) (loss=0.00839): 100%|| 15/15 [00:03<00:00,  4.52it/s]\n","Training (262 / 1000 Steps) (loss=0.01854): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (263 / 1000 Steps) (loss=0.00180): 100%|| 15/15 [00:03<00:00,  4.91it/s]\n","Training (264 / 1000 Steps) (loss=0.00342): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (265 / 1000 Steps) (loss=0.00042): 100%|| 15/15 [00:03<00:00,  4.93it/s]\n","Training (266 / 1000 Steps) (loss=0.00039): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (267 / 1000 Steps) (loss=0.00167): 100%|| 15/15 [00:03<00:00,  4.91it/s]\n","Training (268 / 1000 Steps) (loss=0.00125): 100%|| 15/15 [00:03<00:00,  4.92it/s]\n","Training (269 / 1000 Steps) (loss=0.09008): 100%|| 15/15 [00:03<00:00,  4.98it/s]\n","Training (270 / 1000 Steps) (loss=0.00112): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (271 / 1000 Steps) (loss=0.00264): 100%|| 15/15 [00:03<00:00,  4.62it/s]\n","Training (272 / 1000 Steps) (loss=0.00709): 100%|| 15/15 [00:02<00:00,  5.00it/s]\n","Training (273 / 1000 Steps) (loss=0.03298): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (274 / 1000 Steps) (loss=0.03434): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (275 / 1000 Steps) (loss=0.00377): 100%|| 15/15 [00:03<00:00,  4.98it/s]\n","Training (276 / 1000 Steps) (loss=0.00062): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (277 / 1000 Steps) (loss=0.00082): 100%|| 15/15 [00:03<00:00,  5.00it/s]\n","Training (278 / 1000 Steps) (loss=0.00073): 100%|| 15/15 [00:03<00:00,  4.89it/s]\n","Training (279 / 1000 Steps) (loss=0.00181): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (280 / 1000 Steps) (loss=0.00066): 100%|| 15/15 [00:03<00:00,  4.92it/s]\n","Training (281 / 1000 Steps) (loss=0.00708): 100%|| 15/15 [00:03<00:00,  4.94it/s]\n","Training (282 / 1000 Steps) (loss=0.00014): 100%|| 15/15 [00:03<00:00,  4.92it/s]\n","Training (283 / 1000 Steps) (loss=0.01380): 100%|| 15/15 [00:03<00:00,  4.91it/s]\n","Training (284 / 1000 Steps) (loss=0.00035): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (285 / 1000 Steps) (loss=0.00486): 100%|| 15/15 [00:02<00:00,  5.02it/s]\n","Training (286 / 1000 Steps) (loss=0.00167): 100%|| 15/15 [00:03<00:00,  4.94it/s]\n","Training (287 / 1000 Steps) (loss=0.00108): 100%|| 15/15 [00:03<00:00,  4.99it/s]\n","Training (288 / 1000 Steps) (loss=0.00057): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (289 / 1000 Steps) (loss=0.00032): 100%|| 15/15 [00:03<00:00,  4.94it/s]\n","Training (290 / 1000 Steps) (loss=0.00215): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (291 / 1000 Steps) (loss=0.00552): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (292 / 1000 Steps) (loss=0.00026): 100%|| 15/15 [00:02<00:00,  5.08it/s]\n","Training (293 / 1000 Steps) (loss=0.00017): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (294 / 1000 Steps) (loss=0.00089): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (295 / 1000 Steps) (loss=0.00063): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (296 / 1000 Steps) (loss=0.00080): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (297 / 1000 Steps) (loss=0.00005): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (298 / 1000 Steps) (loss=0.00018): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (299 / 1000 Steps) (loss=0.00049): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (300 / 1000 Steps) (loss=0.00348):   0%|| 0/15 [00:00<?, ?it/s]\n","Validating... (loss=X.X):   0%|| 0/3 [00:00<?, ?it/s]\u001b[A\n","Validating... (loss=0.29860):   0%|| 0/3 [00:01<?, ?it/s]\u001b[A\n","Validating... (loss=0.29860):  33%|| 1/3 [00:01<00:03,  1.82s/it]\u001b[A\n","Validating... (loss=0.15187):  33%|| 1/3 [00:02<00:03,  1.82s/it]\u001b[A\n","Validating... (loss=0.15187):  67%|| 2/3 [00:02<00:00,  1.14it/s]\u001b[A\n","Validating... (loss=0.12187): 100%|| 3/3 [00:02<00:00,  1.34it/s]\n","Training (300 / 1000 Steps) (loss=0.00348): 100%|| 15/15 [00:05<00:00,  2.84it/s]\n","Training (301 / 1000 Steps) (loss=0.00037): 100%|| 15/15 [00:03<00:00,  4.60it/s]\n","Training (302 / 1000 Steps) (loss=0.00699): 100%|| 15/15 [00:03<00:00,  3.86it/s]\n","Training (303 / 1000 Steps) (loss=0.00076): 100%|| 15/15 [00:03<00:00,  4.54it/s]\n","Training (304 / 1000 Steps) (loss=0.00222): 100%|| 15/15 [00:03<00:00,  4.95it/s]\n","Training (305 / 1000 Steps) (loss=0.03670): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (306 / 1000 Steps) (loss=0.00050): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (307 / 1000 Steps) (loss=0.00011): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (308 / 1000 Steps) (loss=0.06583): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (309 / 1000 Steps) (loss=0.00371): 100%|| 15/15 [00:03<00:00,  4.60it/s]\n","Training (310 / 1000 Steps) (loss=0.00107): 100%|| 15/15 [00:03<00:00,  4.62it/s]\n","Training (311 / 1000 Steps) (loss=0.00021): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (312 / 1000 Steps) (loss=0.00013): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (313 / 1000 Steps) (loss=0.00562): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (314 / 1000 Steps) (loss=0.06803): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (315 / 1000 Steps) (loss=0.22530): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (316 / 1000 Steps) (loss=0.00037): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (317 / 1000 Steps) (loss=0.01004): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (318 / 1000 Steps) (loss=0.01471): 100%|| 15/15 [00:03<00:00,  4.67it/s]\n","Training (319 / 1000 Steps) (loss=0.00280): 100%|| 15/15 [00:03<00:00,  4.91it/s]\n","Training (320 / 1000 Steps) (loss=0.00124): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (321 / 1000 Steps) (loss=0.00025): 100%|| 15/15 [00:03<00:00,  4.56it/s]\n","Training (322 / 1000 Steps) (loss=0.00360): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (323 / 1000 Steps) (loss=0.00015): 100%|| 15/15 [00:03<00:00,  4.98it/s]\n","Training (324 / 1000 Steps) (loss=0.00026): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (325 / 1000 Steps) (loss=0.00079): 100%|| 15/15 [00:03<00:00,  4.64it/s]\n","Training (326 / 1000 Steps) (loss=0.00421): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (327 / 1000 Steps) (loss=0.00011): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (328 / 1000 Steps) (loss=0.00012): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (329 / 1000 Steps) (loss=0.05818): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (330 / 1000 Steps) (loss=0.00037): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (331 / 1000 Steps) (loss=0.00913): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (332 / 1000 Steps) (loss=0.00196): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (333 / 1000 Steps) (loss=0.00093): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (334 / 1000 Steps) (loss=0.02835): 100%|| 15/15 [00:03<00:00,  4.97it/s]\n","Training (335 / 1000 Steps) (loss=0.00567): 100%|| 15/15 [00:03<00:00,  4.94it/s]\n","Training (336 / 1000 Steps) (loss=0.00037): 100%|| 15/15 [00:03<00:00,  4.65it/s]\n","Training (337 / 1000 Steps) (loss=0.00102): 100%|| 15/15 [00:03<00:00,  4.53it/s]\n","Training (338 / 1000 Steps) (loss=0.00010): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (339 / 1000 Steps) (loss=0.00062): 100%|| 15/15 [00:03<00:00,  4.94it/s]\n","Training (340 / 1000 Steps) (loss=0.00007): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (341 / 1000 Steps) (loss=0.00705): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (342 / 1000 Steps) (loss=0.00016): 100%|| 15/15 [00:03<00:00,  4.62it/s]\n","Training (343 / 1000 Steps) (loss=0.00003): 100%|| 15/15 [00:03<00:00,  4.56it/s]\n","Training (344 / 1000 Steps) (loss=0.00011): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (345 / 1000 Steps) (loss=0.00685): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (346 / 1000 Steps) (loss=0.00018): 100%|| 15/15 [00:03<00:00,  4.95it/s]\n","Training (347 / 1000 Steps) (loss=0.00025): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (348 / 1000 Steps) (loss=0.00006): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (349 / 1000 Steps) (loss=0.00469): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (350 / 1000 Steps) (loss=0.01137):   0%|| 0/15 [00:01<?, ?it/s]\n","Validating... (loss=X.X):   0%|| 0/3 [00:00<?, ?it/s]\u001b[A\n","Validating... (loss=0.27325):   0%|| 0/3 [00:01<?, ?it/s]\u001b[A\n","Validating... (loss=0.27325):  33%|| 1/3 [00:01<00:03,  1.51s/it]\u001b[A\n","Validating... (loss=0.16055):  33%|| 1/3 [00:01<00:03,  1.51s/it]\u001b[A\n","Validating... (loss=0.16055):  67%|| 2/3 [00:01<00:00,  1.34it/s]\u001b[A\n","Validating... (loss=0.19586): 100%|| 3/3 [00:01<00:00,  1.55it/s]\n","Training (350 / 1000 Steps) (loss=0.01137): 100%|| 15/15 [00:05<00:00,  2.87it/s]\n","Training (351 / 1000 Steps) (loss=0.00023): 100%|| 15/15 [00:03<00:00,  4.89it/s]\n","Training (352 / 1000 Steps) (loss=0.00963): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (353 / 1000 Steps) (loss=0.00573): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (354 / 1000 Steps) (loss=0.00050): 100%|| 15/15 [00:03<00:00,  4.89it/s]\n","Training (355 / 1000 Steps) (loss=0.00038): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (356 / 1000 Steps) (loss=0.00046): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (357 / 1000 Steps) (loss=0.00193): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (358 / 1000 Steps) (loss=0.00004): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (359 / 1000 Steps) (loss=0.00022): 100%|| 15/15 [00:03<00:00,  4.67it/s]\n","Training (360 / 1000 Steps) (loss=0.00399): 100%|| 15/15 [00:03<00:00,  3.83it/s]\n","Training (361 / 1000 Steps) (loss=0.00033): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (362 / 1000 Steps) (loss=0.00130): 100%|| 15/15 [00:03<00:00,  4.53it/s]\n","Training (363 / 1000 Steps) (loss=0.00256): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (364 / 1000 Steps) (loss=0.05177): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (365 / 1000 Steps) (loss=0.00010): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (366 / 1000 Steps) (loss=0.00064): 100%|| 15/15 [00:03<00:00,  4.65it/s]\n","Training (367 / 1000 Steps) (loss=0.00009): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (368 / 1000 Steps) (loss=0.00083): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (369 / 1000 Steps) (loss=0.00097): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (370 / 1000 Steps) (loss=0.00292): 100%|| 15/15 [00:03<00:00,  4.60it/s]\n","Training (371 / 1000 Steps) (loss=0.00779): 100%|| 15/15 [00:03<00:00,  5.00it/s]\n","Training (372 / 1000 Steps) (loss=0.00025): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (373 / 1000 Steps) (loss=0.00291): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (374 / 1000 Steps) (loss=0.01731): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (375 / 1000 Steps) (loss=0.00024): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (376 / 1000 Steps) (loss=0.00065): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (377 / 1000 Steps) (loss=0.00329): 100%|| 15/15 [00:03<00:00,  4.97it/s]\n","Training (378 / 1000 Steps) (loss=0.02182): 100%|| 15/15 [00:03<00:00,  4.95it/s]\n","Training (379 / 1000 Steps) (loss=0.00047): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (380 / 1000 Steps) (loss=0.00094): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (381 / 1000 Steps) (loss=0.00958): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (382 / 1000 Steps) (loss=0.01252): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (383 / 1000 Steps) (loss=0.00183): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (384 / 1000 Steps) (loss=0.00021): 100%|| 15/15 [00:03<00:00,  4.93it/s]\n","Training (385 / 1000 Steps) (loss=0.03884): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (386 / 1000 Steps) (loss=0.00027): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (387 / 1000 Steps) (loss=0.00004): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (388 / 1000 Steps) (loss=0.00270): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (389 / 1000 Steps) (loss=0.00292): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (390 / 1000 Steps) (loss=0.00020): 100%|| 15/15 [00:03<00:00,  4.49it/s]\n","Training (391 / 1000 Steps) (loss=0.00662): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (392 / 1000 Steps) (loss=0.00271): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (393 / 1000 Steps) (loss=0.00006): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (394 / 1000 Steps) (loss=0.00091): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (395 / 1000 Steps) (loss=0.05660): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (396 / 1000 Steps) (loss=0.00015): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (397 / 1000 Steps) (loss=0.00006): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (398 / 1000 Steps) (loss=0.00043): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (399 / 1000 Steps) (loss=0.00095): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (400 / 1000 Steps) (loss=0.00056):   0%|| 0/15 [00:00<?, ?it/s]\n","Validating... (loss=X.X):   0%|| 0/3 [00:00<?, ?it/s]\u001b[A\n","Validating... (loss=0.18165):   0%|| 0/3 [00:01<?, ?it/s]\u001b[A\n","Validating... (loss=0.18165):  33%|| 1/3 [00:01<00:03,  1.71s/it]\u001b[A\n","Validating... (loss=0.02146):  33%|| 1/3 [00:01<00:03,  1.71s/it]\u001b[A\n","Validating... (loss=0.02146):  67%|| 2/3 [00:01<00:00,  1.21it/s]\u001b[A\n","Validating... (loss=0.46473): 100%|| 3/3 [00:02<00:00,  1.40it/s]\n","Training (400 / 1000 Steps) (loss=0.00056): 100%|| 15/15 [00:05<00:00,  2.82it/s]\n","Training (401 / 1000 Steps) (loss=0.00037): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (402 / 1000 Steps) (loss=0.00120): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (403 / 1000 Steps) (loss=0.00013): 100%|| 15/15 [00:03<00:00,  4.89it/s]\n","Training (404 / 1000 Steps) (loss=0.00070): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (405 / 1000 Steps) (loss=0.04953): 100%|| 15/15 [00:02<00:00,  5.01it/s]\n","Training (406 / 1000 Steps) (loss=0.00004): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (407 / 1000 Steps) (loss=0.00040): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (408 / 1000 Steps) (loss=0.00016): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (409 / 1000 Steps) (loss=0.00011): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (410 / 1000 Steps) (loss=0.00041): 100%|| 15/15 [00:03<00:00,  4.89it/s]\n","Training (411 / 1000 Steps) (loss=0.00648): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (412 / 1000 Steps) (loss=0.00018): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (413 / 1000 Steps) (loss=0.00658): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (414 / 1000 Steps) (loss=0.00019): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (415 / 1000 Steps) (loss=0.00024): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (416 / 1000 Steps) (loss=0.00198): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (417 / 1000 Steps) (loss=0.01141): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (418 / 1000 Steps) (loss=0.00052): 100%|| 15/15 [00:04<00:00,  3.56it/s]\n","Training (419 / 1000 Steps) (loss=0.00073): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (420 / 1000 Steps) (loss=0.00021): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (421 / 1000 Steps) (loss=0.00007): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (422 / 1000 Steps) (loss=0.05199): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (423 / 1000 Steps) (loss=0.00093): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (424 / 1000 Steps) (loss=0.07556): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (425 / 1000 Steps) (loss=0.09151): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (426 / 1000 Steps) (loss=0.00134): 100%|| 15/15 [00:03<00:00,  4.89it/s]\n","Training (427 / 1000 Steps) (loss=0.00341): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (428 / 1000 Steps) (loss=0.00463): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (429 / 1000 Steps) (loss=0.00096): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (430 / 1000 Steps) (loss=0.00090): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (431 / 1000 Steps) (loss=0.00002): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (432 / 1000 Steps) (loss=0.00009): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (433 / 1000 Steps) (loss=0.00148): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (434 / 1000 Steps) (loss=0.00008): 100%|| 15/15 [00:03<00:00,  4.50it/s]\n","Training (435 / 1000 Steps) (loss=0.00083): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (436 / 1000 Steps) (loss=0.00002): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (437 / 1000 Steps) (loss=0.04269): 100%|| 15/15 [00:03<00:00,  4.55it/s]\n","Training (438 / 1000 Steps) (loss=0.00062): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (439 / 1000 Steps) (loss=0.01079): 100%|| 15/15 [00:03<00:00,  4.93it/s]\n","Training (440 / 1000 Steps) (loss=0.00068): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (441 / 1000 Steps) (loss=0.00054): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (442 / 1000 Steps) (loss=0.00021): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (443 / 1000 Steps) (loss=0.02199): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (444 / 1000 Steps) (loss=0.00788): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (445 / 1000 Steps) (loss=0.00011): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (446 / 1000 Steps) (loss=0.00082): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (447 / 1000 Steps) (loss=0.00022): 100%|| 15/15 [00:03<00:00,  4.92it/s]\n","Training (448 / 1000 Steps) (loss=0.00263): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (449 / 1000 Steps) (loss=0.00048): 100%|| 15/15 [00:03<00:00,  4.55it/s]\n","Training (450 / 1000 Steps) (loss=0.00009):   0%|| 0/15 [00:00<?, ?it/s]\n","Validating... (loss=X.X):   0%|| 0/3 [00:00<?, ?it/s]\u001b[A\n","Validating... (loss=0.20017):   0%|| 0/3 [00:01<?, ?it/s]\u001b[A\n","Validating... (loss=0.20017):  33%|| 1/3 [00:01<00:03,  1.69s/it]\u001b[A\n","Validating... (loss=0.17403):  33%|| 1/3 [00:01<00:03,  1.69s/it]\u001b[A\n","Validating... (loss=0.17403):  67%|| 2/3 [00:01<00:00,  1.23it/s]\u001b[A\n","Validating... (loss=0.03006): 100%|| 3/3 [00:02<00:00,  1.42it/s]\n","Training (450 / 1000 Steps) (loss=0.00009): 100%|| 15/15 [00:05<00:00,  2.87it/s]\n","Training (451 / 1000 Steps) (loss=0.00010): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (452 / 1000 Steps) (loss=0.00055): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (453 / 1000 Steps) (loss=0.00015): 100%|| 15/15 [00:03<00:00,  4.68it/s]\n","Training (454 / 1000 Steps) (loss=0.00157): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (455 / 1000 Steps) (loss=0.00010): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (456 / 1000 Steps) (loss=0.00524): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (457 / 1000 Steps) (loss=0.00015): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (458 / 1000 Steps) (loss=0.00025): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (459 / 1000 Steps) (loss=0.00004): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (460 / 1000 Steps) (loss=0.00119): 100%|| 15/15 [00:03<00:00,  4.93it/s]\n","Training (461 / 1000 Steps) (loss=0.00030): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (462 / 1000 Steps) (loss=0.00090): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (463 / 1000 Steps) (loss=0.00011): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (464 / 1000 Steps) (loss=0.00039): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (465 / 1000 Steps) (loss=0.04988): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (466 / 1000 Steps) (loss=0.00006): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (467 / 1000 Steps) (loss=0.00112): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (468 / 1000 Steps) (loss=0.00021): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (469 / 1000 Steps) (loss=0.00700): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (470 / 1000 Steps) (loss=0.11813): 100%|| 15/15 [00:03<00:00,  4.93it/s]\n","Training (471 / 1000 Steps) (loss=0.00004): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (472 / 1000 Steps) (loss=0.00187): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (473 / 1000 Steps) (loss=0.00563): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (474 / 1000 Steps) (loss=0.00061): 100%|| 15/15 [00:03<00:00,  4.55it/s]\n","Training (475 / 1000 Steps) (loss=0.00063): 100%|| 15/15 [00:03<00:00,  4.52it/s]\n","Training (476 / 1000 Steps) (loss=0.03201): 100%|| 15/15 [00:03<00:00,  4.40it/s]\n","Training (477 / 1000 Steps) (loss=0.00003): 100%|| 15/15 [00:03<00:00,  4.13it/s]\n","Training (478 / 1000 Steps) (loss=0.00021): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (479 / 1000 Steps) (loss=0.00308): 100%|| 15/15 [00:03<00:00,  4.65it/s]\n","Training (480 / 1000 Steps) (loss=0.00420): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (481 / 1000 Steps) (loss=0.00071): 100%|| 15/15 [00:03<00:00,  4.89it/s]\n","Training (482 / 1000 Steps) (loss=0.00002): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (483 / 1000 Steps) (loss=0.00351): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (484 / 1000 Steps) (loss=0.02947): 100%|| 15/15 [00:03<00:00,  4.91it/s]\n","Training (485 / 1000 Steps) (loss=0.00003): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (486 / 1000 Steps) (loss=0.00039): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (487 / 1000 Steps) (loss=0.00057): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (488 / 1000 Steps) (loss=0.00009): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (489 / 1000 Steps) (loss=0.00916): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (490 / 1000 Steps) (loss=0.00014): 100%|| 15/15 [00:03<00:00,  4.95it/s]\n","Training (491 / 1000 Steps) (loss=0.00003): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (492 / 1000 Steps) (loss=0.00011): 100%|| 15/15 [00:03<00:00,  4.89it/s]\n","Training (493 / 1000 Steps) (loss=0.00001): 100%|| 15/15 [00:03<00:00,  4.89it/s]\n","Training (494 / 1000 Steps) (loss=0.10672): 100%|| 15/15 [00:03<00:00,  4.92it/s]\n","Training (495 / 1000 Steps) (loss=0.00022): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (496 / 1000 Steps) (loss=0.00333): 100%|| 15/15 [00:03<00:00,  4.55it/s]\n","Training (497 / 1000 Steps) (loss=0.00003): 100%|| 15/15 [00:03<00:00,  4.63it/s]\n","Training (498 / 1000 Steps) (loss=0.00006): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (499 / 1000 Steps) (loss=0.00161): 100%|| 15/15 [00:03<00:00,  4.92it/s]\n","Training (500 / 1000 Steps) (loss=0.00086):   0%|| 0/15 [00:00<?, ?it/s]\n","Validating... (loss=X.X):   0%|| 0/3 [00:00<?, ?it/s]\u001b[A\n","Validating... (loss=0.10943):   0%|| 0/3 [00:01<?, ?it/s]\u001b[A\n","Validating... (loss=0.10943):  33%|| 1/3 [00:01<00:03,  1.64s/it]\u001b[A\n","Validating... (loss=0.17703):  33%|| 1/3 [00:01<00:03,  1.64s/it]\u001b[A\n","Validating... (loss=0.17703):  67%|| 2/3 [00:01<00:00,  1.25it/s]\u001b[A\n","Validating... (loss=0.47130): 100%|| 3/3 [00:02<00:00,  1.46it/s]\n","Training (500 / 1000 Steps) (loss=0.00086): 100%|| 15/15 [00:05<00:00,  2.87it/s]\n","Training (501 / 1000 Steps) (loss=0.12091): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (502 / 1000 Steps) (loss=0.15512): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (503 / 1000 Steps) (loss=0.01864): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (504 / 1000 Steps) (loss=0.01218): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (505 / 1000 Steps) (loss=0.00029): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (506 / 1000 Steps) (loss=0.00002): 100%|| 15/15 [00:02<00:00,  5.03it/s]\n","Training (507 / 1000 Steps) (loss=0.00783): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (508 / 1000 Steps) (loss=0.00012): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (509 / 1000 Steps) (loss=0.00008): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (510 / 1000 Steps) (loss=0.00108): 100%|| 15/15 [00:03<00:00,  4.63it/s]\n","Training (511 / 1000 Steps) (loss=0.00029): 100%|| 15/15 [00:03<00:00,  4.91it/s]\n","Training (512 / 1000 Steps) (loss=0.00023): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (513 / 1000 Steps) (loss=0.00450): 100%|| 15/15 [00:03<00:00,  4.93it/s]\n","Training (514 / 1000 Steps) (loss=0.00002): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (515 / 1000 Steps) (loss=0.00039): 100%|| 15/15 [00:03<00:00,  4.89it/s]\n","Training (516 / 1000 Steps) (loss=0.00447): 100%|| 15/15 [00:03<00:00,  4.91it/s]\n","Training (517 / 1000 Steps) (loss=0.10248): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (518 / 1000 Steps) (loss=0.00008): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (519 / 1000 Steps) (loss=0.00001): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (520 / 1000 Steps) (loss=0.18013): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (521 / 1000 Steps) (loss=0.04605): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (522 / 1000 Steps) (loss=0.00775): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (523 / 1000 Steps) (loss=0.00119): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (524 / 1000 Steps) (loss=0.00014): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (525 / 1000 Steps) (loss=0.00010): 100%|| 15/15 [00:03<00:00,  4.95it/s]\n","Training (526 / 1000 Steps) (loss=0.00877): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (527 / 1000 Steps) (loss=0.00025): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (528 / 1000 Steps) (loss=0.00001): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (529 / 1000 Steps) (loss=0.00119): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (530 / 1000 Steps) (loss=0.00014): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (531 / 1000 Steps) (loss=0.00008): 100%|| 15/15 [00:03<00:00,  4.94it/s]\n","Training (532 / 1000 Steps) (loss=0.00054): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (533 / 1000 Steps) (loss=0.00026): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (534 / 1000 Steps) (loss=0.00005): 100%|| 15/15 [00:03<00:00,  4.44it/s]\n","Training (535 / 1000 Steps) (loss=0.00473): 100%|| 15/15 [00:03<00:00,  3.99it/s]\n","Training (536 / 1000 Steps) (loss=0.00014): 100%|| 15/15 [00:03<00:00,  4.58it/s]\n","Training (537 / 1000 Steps) (loss=0.00234): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (538 / 1000 Steps) (loss=0.00550): 100%|| 15/15 [00:03<00:00,  4.91it/s]\n","Training (539 / 1000 Steps) (loss=0.00056): 100%|| 15/15 [00:03<00:00,  4.47it/s]\n","Training (540 / 1000 Steps) (loss=0.00005): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (541 / 1000 Steps) (loss=0.10805): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (542 / 1000 Steps) (loss=0.00148): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (543 / 1000 Steps) (loss=0.00071): 100%|| 15/15 [00:03<00:00,  4.97it/s]\n","Training (544 / 1000 Steps) (loss=0.00008): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (545 / 1000 Steps) (loss=0.26271): 100%|| 15/15 [00:03<00:00,  4.62it/s]\n","Training (546 / 1000 Steps) (loss=0.00011): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (547 / 1000 Steps) (loss=0.00103): 100%|| 15/15 [00:03<00:00,  4.65it/s]\n","Training (548 / 1000 Steps) (loss=0.00046): 100%|| 15/15 [00:03<00:00,  4.55it/s]\n","Training (549 / 1000 Steps) (loss=0.01298): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (550 / 1000 Steps) (loss=0.07865):   0%|| 0/15 [00:00<?, ?it/s]\n","Validating... (loss=X.X):   0%|| 0/3 [00:00<?, ?it/s]\u001b[A\n","Validating... (loss=0.30817):   0%|| 0/3 [00:01<?, ?it/s]\u001b[A\n","Validating... (loss=0.30817):  33%|| 1/3 [00:01<00:03,  1.72s/it]\u001b[A\n","Validating... (loss=0.23084):  33%|| 1/3 [00:01<00:03,  1.72s/it]\u001b[A\n","Validating... (loss=0.23084):  67%|| 2/3 [00:01<00:00,  1.20it/s]\u001b[A\n","Validating... (loss=0.24348): 100%|| 3/3 [00:02<00:00,  1.39it/s]\n","Training (550 / 1000 Steps) (loss=0.07865): 100%|| 15/15 [00:05<00:00,  2.84it/s]\n","Training (551 / 1000 Steps) (loss=0.00191): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (552 / 1000 Steps) (loss=0.10127): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (553 / 1000 Steps) (loss=0.00363): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (554 / 1000 Steps) (loss=0.02593): 100%|| 15/15 [00:02<00:00,  5.04it/s]\n","Training (555 / 1000 Steps) (loss=0.00043): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (556 / 1000 Steps) (loss=0.00056): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (557 / 1000 Steps) (loss=0.00033): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (558 / 1000 Steps) (loss=0.02108): 100%|| 15/15 [00:02<00:00,  5.06it/s]\n","Training (559 / 1000 Steps) (loss=0.02256): 100%|| 15/15 [00:03<00:00,  4.95it/s]\n","Training (560 / 1000 Steps) (loss=0.00085): 100%|| 15/15 [00:03<00:00,  4.93it/s]\n","Training (561 / 1000 Steps) (loss=0.00025): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (562 / 1000 Steps) (loss=0.00006): 100%|| 15/15 [00:03<00:00,  4.95it/s]\n","Training (563 / 1000 Steps) (loss=0.00005): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (564 / 1000 Steps) (loss=0.00647): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (565 / 1000 Steps) (loss=0.00005): 100%|| 15/15 [00:02<00:00,  5.04it/s]\n","Training (566 / 1000 Steps) (loss=0.00005): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (567 / 1000 Steps) (loss=0.01362): 100%|| 15/15 [00:03<00:00,  4.92it/s]\n","Training (568 / 1000 Steps) (loss=0.00001): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (569 / 1000 Steps) (loss=0.00127): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (570 / 1000 Steps) (loss=0.00897): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (571 / 1000 Steps) (loss=0.00004): 100%|| 15/15 [00:03<00:00,  4.89it/s]\n","Training (572 / 1000 Steps) (loss=0.00019): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (573 / 1000 Steps) (loss=0.00090): 100%|| 15/15 [00:03<00:00,  4.54it/s]\n","Training (574 / 1000 Steps) (loss=0.00001): 100%|| 15/15 [00:03<00:00,  5.00it/s]\n","Training (575 / 1000 Steps) (loss=0.00875): 100%|| 15/15 [00:03<00:00,  4.56it/s]\n","Training (576 / 1000 Steps) (loss=0.00105): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (577 / 1000 Steps) (loss=0.00060): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (578 / 1000 Steps) (loss=0.00014): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (579 / 1000 Steps) (loss=0.00004): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (580 / 1000 Steps) (loss=0.00628): 100%|| 15/15 [00:03<00:00,  4.95it/s]\n","Training (581 / 1000 Steps) (loss=0.00010): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (582 / 1000 Steps) (loss=0.00777): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (583 / 1000 Steps) (loss=0.00008): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (584 / 1000 Steps) (loss=0.00075): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (585 / 1000 Steps) (loss=0.00102): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (586 / 1000 Steps) (loss=0.00043): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (587 / 1000 Steps) (loss=0.00012): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (588 / 1000 Steps) (loss=0.00202): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (589 / 1000 Steps) (loss=0.00042): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (590 / 1000 Steps) (loss=0.00074): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (591 / 1000 Steps) (loss=0.00007): 100%|| 15/15 [00:03<00:00,  4.54it/s]\n","Training (592 / 1000 Steps) (loss=0.03848): 100%|| 15/15 [00:03<00:00,  3.89it/s]\n","Training (593 / 1000 Steps) (loss=0.00007): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (594 / 1000 Steps) (loss=0.00027): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (595 / 1000 Steps) (loss=0.00010): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (596 / 1000 Steps) (loss=0.00015): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (597 / 1000 Steps) (loss=0.00004): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (598 / 1000 Steps) (loss=0.00111): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (599 / 1000 Steps) (loss=0.00005): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (600 / 1000 Steps) (loss=0.00025):   0%|| 0/15 [00:00<?, ?it/s]\n","Validating... (loss=X.X):   0%|| 0/3 [00:00<?, ?it/s]\u001b[A\n","Validating... (loss=0.22076):   0%|| 0/3 [00:01<?, ?it/s]\u001b[A\n","Validating... (loss=0.22076):  33%|| 1/3 [00:01<00:03,  1.69s/it]\u001b[A\n","Validating... (loss=0.05341):  33%|| 1/3 [00:01<00:03,  1.69s/it]\u001b[A\n","Validating... (loss=0.05341):  67%|| 2/3 [00:01<00:00,  1.19it/s]\u001b[A\n","Validating... (loss=0.04862): 100%|| 3/3 [00:02<00:00,  1.39it/s]\n","Training (600 / 1000 Steps) (loss=0.00025): 100%|| 15/15 [00:05<00:00,  2.88it/s]\n","Training (601 / 1000 Steps) (loss=0.00409): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (602 / 1000 Steps) (loss=0.00002): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (603 / 1000 Steps) (loss=0.00661): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (604 / 1000 Steps) (loss=0.00129): 100%|| 15/15 [00:03<00:00,  4.92it/s]\n","Training (605 / 1000 Steps) (loss=0.00051): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (606 / 1000 Steps) (loss=0.00092): 100%|| 15/15 [00:03<00:00,  4.89it/s]\n","Training (607 / 1000 Steps) (loss=0.04995): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (608 / 1000 Steps) (loss=0.00004): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (609 / 1000 Steps) (loss=0.00129): 100%|| 15/15 [00:03<00:00,  4.93it/s]\n","Training (610 / 1000 Steps) (loss=0.00072): 100%|| 15/15 [00:03<00:00,  4.94it/s]\n","Training (611 / 1000 Steps) (loss=0.00007): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (612 / 1000 Steps) (loss=0.00062): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (613 / 1000 Steps) (loss=0.00174): 100%|| 15/15 [00:03<00:00,  4.96it/s]\n","Training (614 / 1000 Steps) (loss=0.00007): 100%|| 15/15 [00:03<00:00,  4.93it/s]\n","Training (615 / 1000 Steps) (loss=0.00026): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (616 / 1000 Steps) (loss=0.00017): 100%|| 15/15 [00:03<00:00,  4.94it/s]\n","Training (617 / 1000 Steps) (loss=0.00067): 100%|| 15/15 [00:03<00:00,  4.62it/s]\n","Training (618 / 1000 Steps) (loss=0.00004): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (619 / 1000 Steps) (loss=0.00003): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (620 / 1000 Steps) (loss=0.00044): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (621 / 1000 Steps) (loss=0.00028): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (622 / 1000 Steps) (loss=0.00446): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (623 / 1000 Steps) (loss=0.00024): 100%|| 15/15 [00:03<00:00,  4.92it/s]\n","Training (624 / 1000 Steps) (loss=0.00930): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (625 / 1000 Steps) (loss=0.00047): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (626 / 1000 Steps) (loss=0.00129): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (627 / 1000 Steps) (loss=0.00011): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (628 / 1000 Steps) (loss=0.02588): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (629 / 1000 Steps) (loss=0.00024): 100%|| 15/15 [00:03<00:00,  4.92it/s]\n","Training (630 / 1000 Steps) (loss=0.00001): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (631 / 1000 Steps) (loss=0.00058): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (632 / 1000 Steps) (loss=0.00006): 100%|| 15/15 [00:02<00:00,  5.01it/s]\n","Training (633 / 1000 Steps) (loss=0.00001): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (634 / 1000 Steps) (loss=0.00002): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (635 / 1000 Steps) (loss=0.00051): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (636 / 1000 Steps) (loss=0.00067): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (637 / 1000 Steps) (loss=0.00047): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (638 / 1000 Steps) (loss=0.00066): 100%|| 15/15 [00:02<00:00,  5.03it/s]\n","Training (639 / 1000 Steps) (loss=0.00008): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (640 / 1000 Steps) (loss=0.00010): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (641 / 1000 Steps) (loss=0.00048): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (642 / 1000 Steps) (loss=0.00069): 100%|| 15/15 [00:03<00:00,  4.52it/s]\n","Training (643 / 1000 Steps) (loss=0.00029): 100%|| 15/15 [00:03<00:00,  4.93it/s]\n","Training (644 / 1000 Steps) (loss=0.00114): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (645 / 1000 Steps) (loss=0.00007): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (646 / 1000 Steps) (loss=0.00287): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (647 / 1000 Steps) (loss=0.00324): 100%|| 15/15 [00:03<00:00,  4.62it/s]\n","Training (648 / 1000 Steps) (loss=0.00010): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (649 / 1000 Steps) (loss=0.00003): 100%|| 15/15 [00:03<00:00,  4.63it/s]\n","Training (650 / 1000 Steps) (loss=0.00996):   0%|| 0/15 [00:01<?, ?it/s]\n","Validating... (loss=X.X):   0%|| 0/3 [00:00<?, ?it/s]\u001b[A\n","Validating... (loss=0.41609):   0%|| 0/3 [00:01<?, ?it/s]\u001b[A\n","Validating... (loss=0.41609):  33%|| 1/3 [00:01<00:03,  1.78s/it]\u001b[A\n","Validating... (loss=0.19814):  33%|| 1/3 [00:01<00:03,  1.78s/it]\u001b[A\n","Validating... (loss=0.19814):  67%|| 2/3 [00:01<00:00,  1.17it/s]\u001b[A\n","Validating... (loss=0.15165): 100%|| 3/3 [00:02<00:00,  1.37it/s]\n","Training (650 / 1000 Steps) (loss=0.00996): 100%|| 15/15 [00:05<00:00,  2.57it/s]\n","Training (651 / 1000 Steps) (loss=0.00557): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (652 / 1000 Steps) (loss=0.00033): 100%|| 15/15 [00:03<00:00,  4.93it/s]\n","Training (653 / 1000 Steps) (loss=0.01456): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (654 / 1000 Steps) (loss=0.00005): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (655 / 1000 Steps) (loss=0.00025): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (656 / 1000 Steps) (loss=0.02108): 100%|| 15/15 [00:03<00:00,  4.93it/s]\n","Training (657 / 1000 Steps) (loss=0.00071): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (658 / 1000 Steps) (loss=0.00017): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (659 / 1000 Steps) (loss=0.00023): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (660 / 1000 Steps) (loss=0.03392): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (661 / 1000 Steps) (loss=0.00048): 100%|| 15/15 [00:03<00:00,  4.98it/s]\n","Training (662 / 1000 Steps) (loss=0.00055): 100%|| 15/15 [00:03<00:00,  4.94it/s]\n","Training (663 / 1000 Steps) (loss=0.00043): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (664 / 1000 Steps) (loss=0.00125): 100%|| 15/15 [00:03<00:00,  4.47it/s]\n","Training (665 / 1000 Steps) (loss=0.00020): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (666 / 1000 Steps) (loss=0.00012): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (667 / 1000 Steps) (loss=0.00007): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (668 / 1000 Steps) (loss=0.00034): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (669 / 1000 Steps) (loss=0.00205): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (670 / 1000 Steps) (loss=0.00056): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (671 / 1000 Steps) (loss=0.00128): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (672 / 1000 Steps) (loss=0.00056): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (673 / 1000 Steps) (loss=0.00003): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (674 / 1000 Steps) (loss=0.00024): 100%|| 15/15 [00:03<00:00,  4.48it/s]\n","Training (675 / 1000 Steps) (loss=0.00014): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (676 / 1000 Steps) (loss=0.00031): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (677 / 1000 Steps) (loss=0.00004): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (678 / 1000 Steps) (loss=0.00132): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (679 / 1000 Steps) (loss=0.00036): 100%|| 15/15 [00:03<00:00,  4.64it/s]\n","Training (680 / 1000 Steps) (loss=0.00026): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (681 / 1000 Steps) (loss=0.03226): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (682 / 1000 Steps) (loss=0.00017): 100%|| 15/15 [00:03<00:00,  4.66it/s]\n","Training (683 / 1000 Steps) (loss=0.00002): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (684 / 1000 Steps) (loss=0.00341): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (685 / 1000 Steps) (loss=0.00050): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (686 / 1000 Steps) (loss=0.00003): 100%|| 15/15 [00:03<00:00,  4.63it/s]\n","Training (687 / 1000 Steps) (loss=0.00001): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (688 / 1000 Steps) (loss=0.00003): 100%|| 15/15 [00:03<00:00,  4.94it/s]\n","Training (689 / 1000 Steps) (loss=0.00198): 100%|| 15/15 [00:03<00:00,  4.93it/s]\n","Training (690 / 1000 Steps) (loss=0.00002): 100%|| 15/15 [00:03<00:00,  4.93it/s]\n","Training (691 / 1000 Steps) (loss=0.00670): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (692 / 1000 Steps) (loss=0.00017): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (693 / 1000 Steps) (loss=0.00026): 100%|| 15/15 [00:03<00:00,  4.95it/s]\n","Training (694 / 1000 Steps) (loss=0.00176): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (695 / 1000 Steps) (loss=0.00062): 100%|| 15/15 [00:03<00:00,  4.51it/s]\n","Training (696 / 1000 Steps) (loss=0.00012): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (697 / 1000 Steps) (loss=0.00022): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (698 / 1000 Steps) (loss=0.00716): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (699 / 1000 Steps) (loss=0.00014): 100%|| 15/15 [00:03<00:00,  4.61it/s]\n","Training (700 / 1000 Steps) (loss=0.00215):   0%|| 0/15 [00:00<?, ?it/s]\n","Validating... (loss=X.X):   0%|| 0/3 [00:00<?, ?it/s]\u001b[A\n","Validating... (loss=0.26631):   0%|| 0/3 [00:01<?, ?it/s]\u001b[A\n","Validating... (loss=0.26631):  33%|| 1/3 [00:01<00:03,  1.99s/it]\u001b[A\n","Validating... (loss=0.29549):  33%|| 1/3 [00:02<00:03,  1.99s/it]\u001b[A\n","Validating... (loss=0.29549):  67%|| 2/3 [00:02<00:00,  1.06it/s]\u001b[A\n","Validating... (loss=0.01979): 100%|| 3/3 [00:02<00:00,  1.24it/s]\n","Training (700 / 1000 Steps) (loss=0.00215): 100%|| 15/15 [00:05<00:00,  2.79it/s]\n","Training (701 / 1000 Steps) (loss=0.00111): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (702 / 1000 Steps) (loss=0.00666): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (703 / 1000 Steps) (loss=0.00056): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (704 / 1000 Steps) (loss=0.00022): 100%|| 15/15 [00:03<00:00,  4.67it/s]\n","Training (705 / 1000 Steps) (loss=0.00015): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (706 / 1000 Steps) (loss=0.00800): 100%|| 15/15 [00:04<00:00,  3.72it/s]\n","Training (707 / 1000 Steps) (loss=0.00504): 100%|| 15/15 [00:03<00:00,  4.47it/s]\n","Training (708 / 1000 Steps) (loss=0.00070): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (709 / 1000 Steps) (loss=0.00884): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (710 / 1000 Steps) (loss=0.00033): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (711 / 1000 Steps) (loss=0.04616): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (712 / 1000 Steps) (loss=0.00026): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (713 / 1000 Steps) (loss=0.00158): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (714 / 1000 Steps) (loss=0.00010): 100%|| 15/15 [00:03<00:00,  4.52it/s]\n","Training (715 / 1000 Steps) (loss=0.00028): 100%|| 15/15 [00:03<00:00,  4.63it/s]\n","Training (716 / 1000 Steps) (loss=0.00080): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (717 / 1000 Steps) (loss=0.00006): 100%|| 15/15 [00:03<00:00,  4.68it/s]\n","Training (718 / 1000 Steps) (loss=0.00238): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (719 / 1000 Steps) (loss=0.00015): 100%|| 15/15 [00:03<00:00,  4.62it/s]\n","Training (720 / 1000 Steps) (loss=0.00392): 100%|| 15/15 [00:03<00:00,  4.93it/s]\n","Training (721 / 1000 Steps) (loss=0.04666): 100%|| 15/15 [00:03<00:00,  4.93it/s]\n","Training (722 / 1000 Steps) (loss=0.00009): 100%|| 15/15 [00:03<00:00,  4.92it/s]\n","Training (723 / 1000 Steps) (loss=0.00189): 100%|| 15/15 [00:03<00:00,  4.93it/s]\n","Training (724 / 1000 Steps) (loss=0.01661): 100%|| 15/15 [00:03<00:00,  4.65it/s]\n","Training (725 / 1000 Steps) (loss=0.00141): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (726 / 1000 Steps) (loss=0.00255): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (727 / 1000 Steps) (loss=0.00449): 100%|| 15/15 [00:03<00:00,  4.92it/s]\n","Training (728 / 1000 Steps) (loss=0.00002): 100%|| 15/15 [00:03<00:00,  4.89it/s]\n","Training (729 / 1000 Steps) (loss=0.00008): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (730 / 1000 Steps) (loss=0.00896): 100%|| 15/15 [00:03<00:00,  4.65it/s]\n","Training (731 / 1000 Steps) (loss=0.00001): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (732 / 1000 Steps) (loss=0.00211): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (733 / 1000 Steps) (loss=0.00013): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (734 / 1000 Steps) (loss=0.00035): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (735 / 1000 Steps) (loss=0.00034): 100%|| 15/15 [00:03<00:00,  4.62it/s]\n","Training (736 / 1000 Steps) (loss=0.00329): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (737 / 1000 Steps) (loss=0.00001): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (738 / 1000 Steps) (loss=0.00009): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (739 / 1000 Steps) (loss=0.00030): 100%|| 15/15 [00:03<00:00,  4.56it/s]\n","Training (740 / 1000 Steps) (loss=0.00328): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (741 / 1000 Steps) (loss=0.00280): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (742 / 1000 Steps) (loss=0.00015): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (743 / 1000 Steps) (loss=0.00018): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (744 / 1000 Steps) (loss=0.00655): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (745 / 1000 Steps) (loss=0.00031): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (746 / 1000 Steps) (loss=0.00006): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (747 / 1000 Steps) (loss=0.00005): 100%|| 15/15 [00:03<00:00,  4.67it/s]\n","Training (748 / 1000 Steps) (loss=0.00239): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (749 / 1000 Steps) (loss=0.00003): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (750 / 1000 Steps) (loss=0.00093):   0%|| 0/15 [00:01<?, ?it/s]\n","Validating... (loss=X.X):   0%|| 0/3 [00:00<?, ?it/s]\u001b[A\n","Validating... (loss=0.25212):   0%|| 0/3 [00:01<?, ?it/s]\u001b[A\n","Validating... (loss=0.25212):  33%|| 1/3 [00:01<00:03,  1.72s/it]\u001b[A\n","Validating... (loss=0.21985):  33%|| 1/3 [00:01<00:03,  1.72s/it]\u001b[A\n","Validating... (loss=0.21985):  67%|| 2/3 [00:01<00:00,  1.21it/s]\u001b[A\n","Validating... (loss=0.01112):  67%|| 2/3 [00:02<00:00,  1.21it/s]\u001b[A\n","Validating... (loss=0.01112): 100%|| 3/3 [00:02<00:00,  1.38it/s]\n","Training (750 / 1000 Steps) (loss=0.00093): 100%|| 15/15 [00:05<00:00,  2.76it/s]\n","Training (751 / 1000 Steps) (loss=0.04544): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (752 / 1000 Steps) (loss=0.00044): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (753 / 1000 Steps) (loss=0.00100): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (754 / 1000 Steps) (loss=0.00012): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (755 / 1000 Steps) (loss=0.00163): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (756 / 1000 Steps) (loss=0.00011): 100%|| 15/15 [00:03<00:00,  4.62it/s]\n","Training (757 / 1000 Steps) (loss=0.00407): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (758 / 1000 Steps) (loss=0.00016): 100%|| 15/15 [00:03<00:00,  4.92it/s]\n","Training (759 / 1000 Steps) (loss=0.00002): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (760 / 1000 Steps) (loss=0.00351): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (761 / 1000 Steps) (loss=0.00065): 100%|| 15/15 [00:03<00:00,  3.78it/s]\n","Training (762 / 1000 Steps) (loss=0.00002): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (763 / 1000 Steps) (loss=0.00012): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (764 / 1000 Steps) (loss=0.00006): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (765 / 1000 Steps) (loss=0.00013): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (766 / 1000 Steps) (loss=0.00024): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (767 / 1000 Steps) (loss=0.00008): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (768 / 1000 Steps) (loss=0.00095): 100%|| 15/15 [00:03<00:00,  4.64it/s]\n","Training (769 / 1000 Steps) (loss=0.00056): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (770 / 1000 Steps) (loss=0.00089): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (771 / 1000 Steps) (loss=0.00568): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (772 / 1000 Steps) (loss=0.00011): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (773 / 1000 Steps) (loss=0.00104): 100%|| 15/15 [00:03<00:00,  4.95it/s]\n","Training (774 / 1000 Steps) (loss=0.00243): 100%|| 15/15 [00:03<00:00,  4.53it/s]\n","Training (775 / 1000 Steps) (loss=0.02938): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (776 / 1000 Steps) (loss=0.32018): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (777 / 1000 Steps) (loss=0.00011): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (778 / 1000 Steps) (loss=0.00020): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (779 / 1000 Steps) (loss=0.00005): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (780 / 1000 Steps) (loss=0.02855): 100%|| 15/15 [00:03<00:00,  4.94it/s]\n","Training (781 / 1000 Steps) (loss=0.00016): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (782 / 1000 Steps) (loss=0.00088): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (783 / 1000 Steps) (loss=0.00108): 100%|| 15/15 [00:03<00:00,  4.61it/s]\n","Training (784 / 1000 Steps) (loss=0.00135): 100%|| 15/15 [00:03<00:00,  3.97it/s]\n","Training (785 / 1000 Steps) (loss=0.00004): 100%|| 15/15 [00:03<00:00,  3.83it/s]\n","Training (786 / 1000 Steps) (loss=0.00012): 100%|| 15/15 [00:03<00:00,  3.76it/s]\n","Training (787 / 1000 Steps) (loss=0.00676): 100%|| 15/15 [00:03<00:00,  3.91it/s]\n","Training (788 / 1000 Steps) (loss=0.00043): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (789 / 1000 Steps) (loss=0.00268): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (790 / 1000 Steps) (loss=0.00088): 100%|| 15/15 [00:03<00:00,  4.89it/s]\n","Training (791 / 1000 Steps) (loss=0.00046): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (792 / 1000 Steps) (loss=0.00006): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (793 / 1000 Steps) (loss=0.00167): 100%|| 15/15 [00:03<00:00,  4.68it/s]\n","Training (794 / 1000 Steps) (loss=0.00013): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (795 / 1000 Steps) (loss=0.00051): 100%|| 15/15 [00:03<00:00,  4.57it/s]\n","Training (796 / 1000 Steps) (loss=0.00004): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (797 / 1000 Steps) (loss=0.12131): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (798 / 1000 Steps) (loss=0.00243): 100%|| 15/15 [00:03<00:00,  4.85it/s]\n","Training (799 / 1000 Steps) (loss=0.00516): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (800 / 1000 Steps) (loss=0.00018):   0%|| 0/15 [00:00<?, ?it/s]\n","Validating... (loss=X.X):   0%|| 0/3 [00:00<?, ?it/s]\u001b[A\n","Validating... (loss=0.28370):   0%|| 0/3 [00:01<?, ?it/s]\u001b[A\n","Validating... (loss=0.28370):  33%|| 1/3 [00:01<00:03,  1.73s/it]\u001b[A\n","Validating... (loss=0.23866):  33%|| 1/3 [00:01<00:03,  1.73s/it]\u001b[A\n","Validating... (loss=0.23866):  67%|| 2/3 [00:01<00:00,  1.20it/s]\u001b[A\n","Validating... (loss=0.00739): 100%|| 3/3 [00:02<00:00,  1.39it/s]\n","Training (800 / 1000 Steps) (loss=0.00018): 100%|| 15/15 [00:05<00:00,  2.82it/s]\n","Training (801 / 1000 Steps) (loss=0.00004): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (802 / 1000 Steps) (loss=0.00596): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (803 / 1000 Steps) (loss=0.00011): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (804 / 1000 Steps) (loss=0.00026): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (805 / 1000 Steps) (loss=0.00359): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (806 / 1000 Steps) (loss=0.00058): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (807 / 1000 Steps) (loss=0.00003): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (808 / 1000 Steps) (loss=0.00176): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (809 / 1000 Steps) (loss=0.00044): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (810 / 1000 Steps) (loss=0.00058): 100%|| 15/15 [00:03<00:00,  4.61it/s]\n","Training (811 / 1000 Steps) (loss=0.00061): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (812 / 1000 Steps) (loss=0.00009): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (813 / 1000 Steps) (loss=0.00003): 100%|| 15/15 [00:03<00:00,  4.68it/s]\n","Training (814 / 1000 Steps) (loss=0.00028): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (815 / 1000 Steps) (loss=0.00005): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (816 / 1000 Steps) (loss=0.00011): 100%|| 15/15 [00:04<00:00,  3.66it/s]\n","Training (817 / 1000 Steps) (loss=0.00170): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (818 / 1000 Steps) (loss=0.00031): 100%|| 15/15 [00:03<00:00,  4.67it/s]\n","Training (819 / 1000 Steps) (loss=0.00347): 100%|| 15/15 [00:03<00:00,  4.67it/s]\n","Training (820 / 1000 Steps) (loss=0.00235): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (821 / 1000 Steps) (loss=0.00005): 100%|| 15/15 [00:03<00:00,  4.65it/s]\n","Training (822 / 1000 Steps) (loss=0.11673): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (823 / 1000 Steps) (loss=0.00004): 100%|| 15/15 [00:03<00:00,  4.68it/s]\n","Training (824 / 1000 Steps) (loss=0.00107): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (825 / 1000 Steps) (loss=0.00544): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (826 / 1000 Steps) (loss=0.00022): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (827 / 1000 Steps) (loss=0.00001): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (828 / 1000 Steps) (loss=0.00038): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (829 / 1000 Steps) (loss=0.00008): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (830 / 1000 Steps) (loss=0.00055): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (831 / 1000 Steps) (loss=0.00041): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (832 / 1000 Steps) (loss=0.00188): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (833 / 1000 Steps) (loss=0.00053): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (834 / 1000 Steps) (loss=0.00015): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (835 / 1000 Steps) (loss=0.00007): 100%|| 15/15 [00:03<00:00,  3.85it/s]\n","Training (836 / 1000 Steps) (loss=0.00026): 100%|| 15/15 [00:03<00:00,  3.88it/s]\n","Training (837 / 1000 Steps) (loss=0.00017): 100%|| 15/15 [00:03<00:00,  3.90it/s]\n","Training (838 / 1000 Steps) (loss=0.00003): 100%|| 15/15 [00:03<00:00,  3.92it/s]\n","Training (839 / 1000 Steps) (loss=0.00223): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (840 / 1000 Steps) (loss=0.01101): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (841 / 1000 Steps) (loss=0.00365): 100%|| 15/15 [00:03<00:00,  4.83it/s]\n","Training (842 / 1000 Steps) (loss=0.00034): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (843 / 1000 Steps) (loss=0.00008): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (844 / 1000 Steps) (loss=0.00412): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (845 / 1000 Steps) (loss=0.00097): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (846 / 1000 Steps) (loss=0.00094): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (847 / 1000 Steps) (loss=0.00013): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (848 / 1000 Steps) (loss=0.00054): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (849 / 1000 Steps) (loss=0.00031): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (850 / 1000 Steps) (loss=0.01017):   0%|| 0/15 [00:00<?, ?it/s]\n","Validating... (loss=X.X):   0%|| 0/3 [00:00<?, ?it/s]\u001b[A\n","Validating... (loss=0.26361):   0%|| 0/3 [00:01<?, ?it/s]\u001b[A\n","Validating... (loss=0.26361):  33%|| 1/3 [00:01<00:03,  1.66s/it]\u001b[A\n","Validating... (loss=0.23730):  33%|| 1/3 [00:01<00:03,  1.66s/it]\u001b[A\n","Validating... (loss=0.23730):  67%|| 2/3 [00:01<00:00,  1.24it/s]\u001b[A\n","Validating... (loss=0.03983): 100%|| 3/3 [00:02<00:00,  1.43it/s]\n","Training (850 / 1000 Steps) (loss=0.01017): 100%|| 15/15 [00:05<00:00,  2.84it/s]\n","Training (851 / 1000 Steps) (loss=0.00014): 100%|| 15/15 [00:03<00:00,  4.57it/s]\n","Training (852 / 1000 Steps) (loss=0.00418): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (853 / 1000 Steps) (loss=0.00218): 100%|| 15/15 [00:03<00:00,  4.90it/s]\n","Training (854 / 1000 Steps) (loss=0.00172): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (855 / 1000 Steps) (loss=0.00005): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (856 / 1000 Steps) (loss=0.00027): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (857 / 1000 Steps) (loss=0.00144): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (858 / 1000 Steps) (loss=0.00025): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (859 / 1000 Steps) (loss=0.00349): 100%|| 15/15 [00:03<00:00,  4.75it/s]\n","Training (860 / 1000 Steps) (loss=0.00002): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (861 / 1000 Steps) (loss=0.00002): 100%|| 15/15 [00:03<00:00,  4.65it/s]\n","Training (862 / 1000 Steps) (loss=0.00007): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (863 / 1000 Steps) (loss=0.00595): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (864 / 1000 Steps) (loss=0.00012): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (865 / 1000 Steps) (loss=0.00011): 100%|| 15/15 [00:03<00:00,  4.66it/s]\n","Training (866 / 1000 Steps) (loss=0.00053): 100%|| 15/15 [00:03<00:00,  4.92it/s]\n","Training (867 / 1000 Steps) (loss=0.26440): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (868 / 1000 Steps) (loss=0.02300): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (869 / 1000 Steps) (loss=0.00137): 100%|| 15/15 [00:03<00:00,  4.58it/s]\n","Training (870 / 1000 Steps) (loss=0.00204): 100%|| 15/15 [00:03<00:00,  3.84it/s]\n","Training (871 / 1000 Steps) (loss=0.00128): 100%|| 15/15 [00:03<00:00,  4.52it/s]\n","Training (872 / 1000 Steps) (loss=0.00017): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (873 / 1000 Steps) (loss=0.00072): 100%|| 15/15 [00:03<00:00,  4.61it/s]\n","Training (874 / 1000 Steps) (loss=0.00316): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (875 / 1000 Steps) (loss=0.00008): 100%|| 15/15 [00:03<00:00,  4.65it/s]\n","Training (876 / 1000 Steps) (loss=0.00748): 100%|| 15/15 [00:03<00:00,  4.68it/s]\n","Training (877 / 1000 Steps) (loss=0.01800): 100%|| 15/15 [00:03<00:00,  4.68it/s]\n","Training (878 / 1000 Steps) (loss=0.00116): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (879 / 1000 Steps) (loss=0.00007): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (880 / 1000 Steps) (loss=0.00912): 100%|| 15/15 [00:03<00:00,  4.92it/s]\n","Training (881 / 1000 Steps) (loss=0.00148): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (882 / 1000 Steps) (loss=0.00058): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (883 / 1000 Steps) (loss=0.00004): 100%|| 15/15 [00:03<00:00,  4.59it/s]\n","Training (884 / 1000 Steps) (loss=0.00031): 100%|| 15/15 [00:03<00:00,  4.68it/s]\n","Training (885 / 1000 Steps) (loss=0.00054): 100%|| 15/15 [00:03<00:00,  4.88it/s]\n","Training (886 / 1000 Steps) (loss=0.04959): 100%|| 15/15 [00:03<00:00,  3.89it/s]\n","Training (887 / 1000 Steps) (loss=0.00130): 100%|| 15/15 [00:03<00:00,  3.83it/s]\n","Training (888 / 1000 Steps) (loss=0.00195): 100%|| 15/15 [00:03<00:00,  3.89it/s]\n","Training (889 / 1000 Steps) (loss=0.00413): 100%|| 15/15 [00:03<00:00,  3.76it/s]\n","Training (890 / 1000 Steps) (loss=0.00128): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (891 / 1000 Steps) (loss=0.00018): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (892 / 1000 Steps) (loss=0.00057): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (893 / 1000 Steps) (loss=0.00023): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (894 / 1000 Steps) (loss=0.00006): 100%|| 15/15 [00:03<00:00,  4.91it/s]\n","Training (895 / 1000 Steps) (loss=0.00077): 100%|| 15/15 [00:03<00:00,  4.59it/s]\n","Training (896 / 1000 Steps) (loss=0.00005): 100%|| 15/15 [00:03<00:00,  4.64it/s]\n","Training (897 / 1000 Steps) (loss=0.00003): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (898 / 1000 Steps) (loss=0.15761): 100%|| 15/15 [00:03<00:00,  4.68it/s]\n","Training (899 / 1000 Steps) (loss=0.00298): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (900 / 1000 Steps) (loss=0.00085):   0%|| 0/15 [00:00<?, ?it/s]\n","Validating... (loss=X.X):   0%|| 0/3 [00:00<?, ?it/s]\u001b[A\n","Validating... (loss=0.34359):   0%|| 0/3 [00:01<?, ?it/s]\u001b[A\n","Validating... (loss=0.34359):  33%|| 1/3 [00:01<00:03,  1.72s/it]\u001b[A\n","Validating... (loss=0.21296):  33%|| 1/3 [00:01<00:03,  1.72s/it]\u001b[A\n","Validating... (loss=0.21296):  67%|| 2/3 [00:01<00:00,  1.19it/s]\u001b[A\n","Validating... (loss=0.40451): 100%|| 3/3 [00:02<00:00,  1.39it/s]\n","Training (900 / 1000 Steps) (loss=0.00085): 100%|| 15/15 [00:05<00:00,  2.87it/s]\n","Training (901 / 1000 Steps) (loss=0.00446): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (902 / 1000 Steps) (loss=0.00022): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (903 / 1000 Steps) (loss=0.00011): 100%|| 15/15 [00:03<00:00,  4.91it/s]\n","Training (904 / 1000 Steps) (loss=0.00022): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (905 / 1000 Steps) (loss=0.00030): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (906 / 1000 Steps) (loss=0.00050): 100%|| 15/15 [00:03<00:00,  4.65it/s]\n","Training (907 / 1000 Steps) (loss=0.00081): 100%|| 15/15 [00:03<00:00,  4.92it/s]\n","Training (908 / 1000 Steps) (loss=0.00134): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (909 / 1000 Steps) (loss=0.00034): 100%|| 15/15 [00:03<00:00,  4.53it/s]\n","Training (910 / 1000 Steps) (loss=0.00122): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (911 / 1000 Steps) (loss=0.00121): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (912 / 1000 Steps) (loss=0.00013): 100%|| 15/15 [00:03<00:00,  4.86it/s]\n","Training (913 / 1000 Steps) (loss=0.00339): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (914 / 1000 Steps) (loss=0.00020): 100%|| 15/15 [00:03<00:00,  4.66it/s]\n","Training (915 / 1000 Steps) (loss=0.00006): 100%|| 15/15 [00:03<00:00,  4.63it/s]\n","Training (916 / 1000 Steps) (loss=0.00004): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (917 / 1000 Steps) (loss=0.05217): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (918 / 1000 Steps) (loss=0.00056): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (919 / 1000 Steps) (loss=0.00005): 100%|| 15/15 [00:03<00:00,  4.50it/s]\n","Training (920 / 1000 Steps) (loss=0.00137): 100%|| 15/15 [00:03<00:00,  4.65it/s]\n","Training (921 / 1000 Steps) (loss=0.01907): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (922 / 1000 Steps) (loss=0.00155): 100%|| 15/15 [00:03<00:00,  4.40it/s]\n","Training (923 / 1000 Steps) (loss=0.00321): 100%|| 15/15 [00:03<00:00,  4.03it/s]\n","Training (924 / 1000 Steps) (loss=0.00005): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (925 / 1000 Steps) (loss=0.00030): 100%|| 15/15 [00:03<00:00,  4.92it/s]\n","Training (926 / 1000 Steps) (loss=0.00506): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (927 / 1000 Steps) (loss=0.00024): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (928 / 1000 Steps) (loss=0.00122): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (929 / 1000 Steps) (loss=0.00002): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (930 / 1000 Steps) (loss=0.00330): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (931 / 1000 Steps) (loss=0.00008): 100%|| 15/15 [00:03<00:00,  4.63it/s]\n","Training (932 / 1000 Steps) (loss=0.00006): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (933 / 1000 Steps) (loss=0.00015): 100%|| 15/15 [00:03<00:00,  3.86it/s]\n","Training (934 / 1000 Steps) (loss=0.00007): 100%|| 15/15 [00:03<00:00,  3.94it/s]\n","Training (935 / 1000 Steps) (loss=0.01088): 100%|| 15/15 [00:03<00:00,  3.93it/s]\n","Training (936 / 1000 Steps) (loss=0.00019): 100%|| 15/15 [00:03<00:00,  3.93it/s]\n","Training (937 / 1000 Steps) (loss=0.00518): 100%|| 15/15 [00:03<00:00,  3.83it/s]\n","Training (938 / 1000 Steps) (loss=0.00045): 100%|| 15/15 [00:03<00:00,  3.87it/s]\n","Training (939 / 1000 Steps) (loss=0.00030): 100%|| 15/15 [00:03<00:00,  3.88it/s]\n","Training (940 / 1000 Steps) (loss=0.00363): 100%|| 15/15 [00:04<00:00,  3.59it/s]\n","Training (941 / 1000 Steps) (loss=0.00018): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (942 / 1000 Steps) (loss=0.00764): 100%|| 15/15 [00:03<00:00,  4.91it/s]\n","Training (943 / 1000 Steps) (loss=0.00151): 100%|| 15/15 [00:03<00:00,  5.00it/s]\n","Training (944 / 1000 Steps) (loss=0.00074): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (945 / 1000 Steps) (loss=0.00010): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (946 / 1000 Steps) (loss=0.00007): 100%|| 15/15 [00:03<00:00,  4.76it/s]\n","Training (947 / 1000 Steps) (loss=0.01589): 100%|| 15/15 [00:03<00:00,  4.71it/s]\n","Training (948 / 1000 Steps) (loss=0.00019): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (949 / 1000 Steps) (loss=0.00004): 100%|| 15/15 [00:03<00:00,  4.91it/s]\n","Training (950 / 1000 Steps) (loss=0.00016):   0%|| 0/15 [00:00<?, ?it/s]\n","Validating... (loss=X.X):   0%|| 0/3 [00:00<?, ?it/s]\u001b[A\n","Validating... (loss=0.15489):   0%|| 0/3 [00:01<?, ?it/s]\u001b[A\n","Validating... (loss=0.15489):  33%|| 1/3 [00:01<00:03,  1.88s/it]\u001b[A\n","Validating... (loss=0.16622):  33%|| 1/3 [00:02<00:03,  1.88s/it]\u001b[A\n","Validating... (loss=0.16622):  67%|| 2/3 [00:02<00:00,  1.12it/s]\u001b[A\n","Validating... (loss=0.12217): 100%|| 3/3 [00:02<00:00,  1.30it/s]\n","Training (950 / 1000 Steps) (loss=0.00016): 100%|| 15/15 [00:05<00:00,  2.82it/s]\n","Training (951 / 1000 Steps) (loss=0.00003): 100%|| 15/15 [00:03<00:00,  4.79it/s]\n","Training (952 / 1000 Steps) (loss=0.16631): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (953 / 1000 Steps) (loss=0.00006): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (954 / 1000 Steps) (loss=0.00006): 100%|| 15/15 [00:03<00:00,  4.65it/s]\n","Training (955 / 1000 Steps) (loss=0.00009): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (956 / 1000 Steps) (loss=0.00371): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (957 / 1000 Steps) (loss=0.00005): 100%|| 15/15 [00:03<00:00,  4.57it/s]\n","Training (958 / 1000 Steps) (loss=0.00016): 100%|| 15/15 [00:03<00:00,  4.62it/s]\n","Training (959 / 1000 Steps) (loss=0.00098): 100%|| 15/15 [00:03<00:00,  4.44it/s]\n","Training (960 / 1000 Steps) (loss=0.00056): 100%|| 15/15 [00:03<00:00,  4.65it/s]\n","Training (961 / 1000 Steps) (loss=0.00205): 100%|| 15/15 [00:03<00:00,  4.63it/s]\n","Training (962 / 1000 Steps) (loss=0.08987): 100%|| 15/15 [00:03<00:00,  4.53it/s]\n","Training (963 / 1000 Steps) (loss=0.00098): 100%|| 15/15 [00:03<00:00,  4.63it/s]\n","Training (964 / 1000 Steps) (loss=0.00182): 100%|| 15/15 [00:03<00:00,  4.87it/s]\n","Training (965 / 1000 Steps) (loss=0.00467): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (966 / 1000 Steps) (loss=0.00052): 100%|| 15/15 [00:03<00:00,  4.66it/s]\n","Training (967 / 1000 Steps) (loss=0.00030): 100%|| 15/15 [00:03<00:00,  4.65it/s]\n","Training (968 / 1000 Steps) (loss=0.01000): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (969 / 1000 Steps) (loss=0.00010): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (970 / 1000 Steps) (loss=0.00047): 100%|| 15/15 [00:03<00:00,  4.59it/s]\n","Training (971 / 1000 Steps) (loss=0.08642): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (972 / 1000 Steps) (loss=0.00004): 100%|| 15/15 [00:03<00:00,  4.81it/s]\n","Training (973 / 1000 Steps) (loss=0.00001): 100%|| 15/15 [00:03<00:00,  4.67it/s]\n","Training (974 / 1000 Steps) (loss=0.00028): 100%|| 15/15 [00:03<00:00,  4.32it/s]\n","Training (975 / 1000 Steps) (loss=0.00141): 100%|| 15/15 [00:03<00:00,  4.16it/s]\n","Training (976 / 1000 Steps) (loss=0.00073): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (977 / 1000 Steps) (loss=0.00101): 100%|| 15/15 [00:03<00:00,  4.82it/s]\n","Training (978 / 1000 Steps) (loss=0.00296): 100%|| 15/15 [00:03<00:00,  4.50it/s]\n","Training (979 / 1000 Steps) (loss=0.00011): 100%|| 15/15 [00:03<00:00,  4.62it/s]\n","Training (980 / 1000 Steps) (loss=0.00395): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (981 / 1000 Steps) (loss=0.00003): 100%|| 15/15 [00:03<00:00,  4.73it/s]\n","Training (982 / 1000 Steps) (loss=0.00076): 100%|| 15/15 [00:03<00:00,  4.78it/s]\n","Training (983 / 1000 Steps) (loss=0.00046): 100%|| 15/15 [00:03<00:00,  4.77it/s]\n","Training (984 / 1000 Steps) (loss=0.00002): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (985 / 1000 Steps) (loss=0.00076): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (986 / 1000 Steps) (loss=0.00446): 100%|| 15/15 [00:03<00:00,  4.56it/s]\n","Training (987 / 1000 Steps) (loss=0.00307): 100%|| 15/15 [00:03<00:00,  4.80it/s]\n","Training (988 / 1000 Steps) (loss=0.01728): 100%|| 15/15 [00:03<00:00,  4.49it/s]\n","Training (989 / 1000 Steps) (loss=0.00043): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (990 / 1000 Steps) (loss=0.00016): 100%|| 15/15 [00:03<00:00,  4.70it/s]\n","Training (991 / 1000 Steps) (loss=0.00022): 100%|| 15/15 [00:03<00:00,  4.57it/s]\n","Training (992 / 1000 Steps) (loss=0.00006): 100%|| 15/15 [00:03<00:00,  4.69it/s]\n","Training (993 / 1000 Steps) (loss=0.00234): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (994 / 1000 Steps) (loss=0.00058): 100%|| 15/15 [00:03<00:00,  4.74it/s]\n","Training (995 / 1000 Steps) (loss=0.00017): 100%|| 15/15 [00:03<00:00,  4.68it/s]\n","Training (996 / 1000 Steps) (loss=0.00213): 100%|| 15/15 [00:03<00:00,  4.84it/s]\n","Training (997 / 1000 Steps) (loss=0.01581): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (998 / 1000 Steps) (loss=0.00009): 100%|| 15/15 [00:03<00:00,  4.67it/s]\n","Training (999 / 1000 Steps) (loss=0.00003): 100%|| 15/15 [00:03<00:00,  4.72it/s]\n","Training (1000 / 1000 Steps) (loss=0.00087):   0%|| 0/15 [00:00<?, ?it/s]\n","Validating... (loss=X.X):   0%|| 0/3 [00:00<?, ?it/s]\u001b[A\n","Validating... (loss=0.34668):   0%|| 0/3 [00:02<?, ?it/s]\u001b[A\n","Validating... (loss=0.34668):  33%|| 1/3 [00:02<00:04,  2.09s/it]\u001b[A\n","Validating... (loss=0.20466):  33%|| 1/3 [00:02<00:04,  2.09s/it]\u001b[A\n","Validating... (loss=0.20466):  67%|| 2/3 [00:02<00:00,  1.02it/s]\u001b[A\n","Validating... (loss=0.27628): 100%|| 3/3 [00:02<00:00,  1.19it/s]\n","Training (1000 / 1000 Steps) (loss=0.00087):   0%|| 0/15 [00:03<?, ?it/s]\n"]}],"source":["if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"colab":{"provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}